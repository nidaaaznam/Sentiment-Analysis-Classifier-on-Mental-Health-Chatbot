{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import and load the data file\n",
    "The data file is in JSON format so we used the json package to parse the JSON file into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!']\n",
    "data_file = open('intents.json', encoding='utf-8').read()\n",
    "intents = json.loads(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocess data\n",
    "1. Tokenization - Process of breaking the whole text into small parts like words. (Iterate through the patterns and tokenize the sentence using nltk.word_tokenize() function)\n",
    "2. Append each word in the words list\n",
    "3. Create a list of classes for tags\n",
    "4. Lemmatization and remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307 documents\n",
      "64 classes ['Lifestyle_treatments', 'Psychotherapy', 'age', 'anger', 'anxiety', 'botgreeting', 'buddy', 'buddyhelp', 'causes', 'ccd', 'couns-contact', 'counselor', 'difference', 'doing_great', 'earlysigns', 'emo-how', 'emo-mstate', 'fact_ADHD_disorder', 'fact_BPD_disorder', 'fact_anxiety', 'fact_depression', 'fact_dissociative_disorder', 'fact_eating_disorder', 'fact_mdd_disorder', 'fact_mood_disorder', 'fact_ocd_disorder', 'fact_personality_disorder', 'fact_psychosis_disorder', 'fact_ptsd_disorder', 'fact_schizo', 'fact_social_anxiety_disorder', 'fail', 'fear', 'function', 'gethelp', 'good_mental_health', 'goodbye', 'greeting', 'greeting2', 'how_are_you', 'intro', 'invalid', 'list-emotions', 'medication', 'mental_health_exercise', 'mental_state', 'mhealth', 'millness', 'mmu', 'mstate-stage', 'neutral', 'percentage', 'random', 'recover', 'relationship', 'responsibilty', 'risk', 'sad', 'session', 'sorry', 'suicidal', 'symptoms', 'talk-buddy', 'thanks']\n",
      "313 unique lemmatized words [\"'s\", \"'ve\", '(', ')', ',', 'a', 'able', 'about', 'affect', 'affected', 'again', 'age', 'agitated', 'alright', 'alternative', 'am', 'among', 'and', 'angry', 'annoyed', 'anxiety', 'anxious', 'any', 'anyone', 'anything', 'appreciate', 'are', 'asking', 'assalamualaikum', 'attention', 'awesome', 'bad', 'basic', 'be', 'been', 'best', 'better', 'between', 'book', 'borderline', 'boring', 'bot', 'boy', 'bring', 'brother', 'buddy', 'buhbye', 'buidling', 'by', 'bye', 'byeee', 'ca', 'can', 'case', 'categorize', 'category', 'cause', 'chance', 'characteristic', 'chatbot', 'check', 'compulsive', 'concentrate', 'conselor', 'contact', 'cool', 'could', 'counseling', 'counsellor', 'counselor', 'crazy', 'cry', 'curable', 'cure', 'cured', 'day', 'deficit', 'define', 'depression', 'depressive', 'describe', 'description', 'detect', 'determine', 'developing', 'diagnosed', 'differ', 'difference', 'different', 'difficult', 'disorder', 'dissociative', 'do', 'doe', 'doing', 'dont', 'down', 'early', 'eating', 'emotion', 'enough', 'establish', 'everything', 'exercise', 'exhausted', 'experience', 'explain', 'facing', 'factor', 'failed', 'far', 'father', 'fear', 'feel', 'feeling', 'find', 'for', 'fought', 'friend', 'from', 'full', 'function', 'get', 'girl', 'glad', 'go', 'going', 'good', 'goodbye', 'great', 'guess', 'ha', 'had', 'happened', 'happy', 'have', 'having', 'health', 'hello', 'help', 'helpful', 'hey', 'heyy', 'hi', 'home', 'hope', 'how', 'human', 'hyperactivity', 'i', 'identify', 'if', 'ill', 'illness', 'im', 'in', 'information', 'irritated', 'is', 'issue', 'it', 'know', 'later', 'lead', 'lifestyle', 'like', 'list', 'lot', 'major', 'malaysia', 'many', 'me', 'mean', 'meaning', 'medication', 'meet', 'meeting', 'meh', 'mental', 'mentally', 'mmu', 'mood', 'most', 'mother', 'much', 'my', 'myself', \"n't\", 'name', 'named', 'need', 'negative', 'neutral', 'nice', 'not', 'noted', 'nothing', 'number', 'obsessive', 'ocd', 'of', 'offended', 'oh', 'ok', 'okay', 'old', 'on', 'ooo', 'or', 'overload', 'owner', 'parent', 'part', 'patient', 'people', 'percentage', 'person', 'personality', 'place', 'post-traumatic', 'problem', 'psychosis', 'psychotherapy', 'purpose', 'reason', 'recover', 'refer', 'regarding', 'relationship', 'remedy', 'responsibility', 'result', 'risk', 'robot', 'root', 'sad', 'same', 'saying', 'scared', 'schizophrenia', 'see', 'seeing', 'seek', 'session', 'shall', 'share', 'should', 'sign', 'sister', 'situation', 'sleep', 'sleeping', 'slot', 'so', 'social', 'someone', 'soon', 'sorry', 'stage', 'state', 'statistic', 'stress', 'struggle', 'student', 'suffer', 'suicidal', 'symptom', 'talk', 'talking', 'tell', 'test', 'text', 'thank', 'thanks', 'that', 'the', 'there', 'they', 'thing', 'thought', 'tired', 'tiring', 'to', 'today', 'treat', 'treatment', 'trigger', 'trouble', 'unit', 'use', 'very', 'wa', 'want', 'warning', 'way', 'we', 'well', 'what', 'whatsup', 'when', 'where', 'whether', 'who', 'whole', 'whom', 'why', 'will', 'with', 'would', 'wow', 'yeah', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "\n",
    "        #tokenize each word\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        \n",
    "        #add documents in the corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "            \n",
    "# lemmaztize and lower each word and remove duplicates\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "# sort classes\n",
    "classes = sorted(list(set(classes)))\n",
    "# documents = combination between patterns and intents\n",
    "print (len(documents), \"documents\")\n",
    "# classes = intents\n",
    "print (len(classes), \"classes\", classes)\n",
    "# words = all words, vocabulary\n",
    "print (len(words), \"unique lemmatized words\", words)\n",
    "\n",
    "pickle.dump(words,open('words.pkl','wb'))\n",
    "pickle.dump(classes,open('classes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create training and testing data\n",
    "Our input will be the pattern and output will be the class our input pattern belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data created\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-affc285901bd>:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  training = np.array(training)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create our training data\n",
    "training = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # lemmatize each word - create base word, in attempt to represent related words\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array with 1, if word match found in current pattern\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    \n",
    "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    \n",
    "    training.append([bag, output_row])\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "# create train and test lists. X - patterns, Y - intents\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n",
    "print(\"Training data created\")\n",
    "print(bag)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(np.array(train_x), np.array(train_y), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'s\",\n",
       " \"'ve\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " 'a',\n",
       " 'able',\n",
       " 'about',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'again',\n",
       " 'age',\n",
       " 'agitated',\n",
       " 'alright',\n",
       " 'alternative',\n",
       " 'am',\n",
       " 'among',\n",
       " 'and',\n",
       " 'angry',\n",
       " 'annoyed',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'any',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'appreciate',\n",
       " 'are',\n",
       " 'asking',\n",
       " 'assalamualaikum',\n",
       " 'attention',\n",
       " 'awesome',\n",
       " 'bad',\n",
       " 'basic',\n",
       " 'be',\n",
       " 'been',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'book',\n",
       " 'borderline',\n",
       " 'boring',\n",
       " 'bot',\n",
       " 'boy',\n",
       " 'bring',\n",
       " 'brother',\n",
       " 'buddy',\n",
       " 'buhbye',\n",
       " 'buidling',\n",
       " 'by',\n",
       " 'bye',\n",
       " 'byeee',\n",
       " 'ca',\n",
       " 'can',\n",
       " 'case',\n",
       " 'categorize',\n",
       " 'category',\n",
       " 'cause',\n",
       " 'chance',\n",
       " 'characteristic',\n",
       " 'chatbot',\n",
       " 'check',\n",
       " 'compulsive',\n",
       " 'concentrate',\n",
       " 'conselor',\n",
       " 'contact',\n",
       " 'cool',\n",
       " 'could',\n",
       " 'counseling',\n",
       " 'counsellor',\n",
       " 'counselor',\n",
       " 'crazy',\n",
       " 'cry',\n",
       " 'curable',\n",
       " 'cure',\n",
       " 'cured',\n",
       " 'day',\n",
       " 'deficit',\n",
       " 'define',\n",
       " 'depression',\n",
       " 'depressive',\n",
       " 'describe',\n",
       " 'description',\n",
       " 'detect',\n",
       " 'determine',\n",
       " 'developing',\n",
       " 'diagnosed',\n",
       " 'differ',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'disorder',\n",
       " 'dissociative',\n",
       " 'do',\n",
       " 'doe',\n",
       " 'doing',\n",
       " 'dont',\n",
       " 'down',\n",
       " 'early',\n",
       " 'eating',\n",
       " 'emotion',\n",
       " 'enough',\n",
       " 'establish',\n",
       " 'everything',\n",
       " 'exercise',\n",
       " 'exhausted',\n",
       " 'experience',\n",
       " 'explain',\n",
       " 'facing',\n",
       " 'factor',\n",
       " 'failed',\n",
       " 'far',\n",
       " 'father',\n",
       " 'fear',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'find',\n",
       " 'for',\n",
       " 'fought',\n",
       " 'friend',\n",
       " 'from',\n",
       " 'full',\n",
       " 'function',\n",
       " 'get',\n",
       " 'girl',\n",
       " 'glad',\n",
       " 'go',\n",
       " 'going',\n",
       " 'good',\n",
       " 'goodbye',\n",
       " 'great',\n",
       " 'guess',\n",
       " 'ha',\n",
       " 'had',\n",
       " 'happened',\n",
       " 'happy',\n",
       " 'have',\n",
       " 'having',\n",
       " 'health',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'hey',\n",
       " 'heyy',\n",
       " 'hi',\n",
       " 'home',\n",
       " 'hope',\n",
       " 'how',\n",
       " 'human',\n",
       " 'hyperactivity',\n",
       " 'i',\n",
       " 'identify',\n",
       " 'if',\n",
       " 'ill',\n",
       " 'illness',\n",
       " 'im',\n",
       " 'in',\n",
       " 'information',\n",
       " 'irritated',\n",
       " 'is',\n",
       " 'issue',\n",
       " 'it',\n",
       " 'know',\n",
       " 'later',\n",
       " 'lead',\n",
       " 'lifestyle',\n",
       " 'like',\n",
       " 'list',\n",
       " 'lot',\n",
       " 'major',\n",
       " 'malaysia',\n",
       " 'many',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meaning',\n",
       " 'medication',\n",
       " 'meet',\n",
       " 'meeting',\n",
       " 'meh',\n",
       " 'mental',\n",
       " 'mentally',\n",
       " 'mmu',\n",
       " 'mood',\n",
       " 'most',\n",
       " 'mother',\n",
       " 'much',\n",
       " 'my',\n",
       " 'myself',\n",
       " \"n't\",\n",
       " 'name',\n",
       " 'named',\n",
       " 'need',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'nice',\n",
       " 'not',\n",
       " 'noted',\n",
       " 'nothing',\n",
       " 'number',\n",
       " 'obsessive',\n",
       " 'ocd',\n",
       " 'of',\n",
       " 'offended',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'on',\n",
       " 'ooo',\n",
       " 'or',\n",
       " 'overload',\n",
       " 'owner',\n",
       " 'parent',\n",
       " 'part',\n",
       " 'patient',\n",
       " 'people',\n",
       " 'percentage',\n",
       " 'person',\n",
       " 'personality',\n",
       " 'place',\n",
       " 'post-traumatic',\n",
       " 'problem',\n",
       " 'psychosis',\n",
       " 'psychotherapy',\n",
       " 'purpose',\n",
       " 'reason',\n",
       " 'recover',\n",
       " 'refer',\n",
       " 'regarding',\n",
       " 'relationship',\n",
       " 'remedy',\n",
       " 'responsibility',\n",
       " 'result',\n",
       " 'risk',\n",
       " 'robot',\n",
       " 'root',\n",
       " 'sad',\n",
       " 'same',\n",
       " 'saying',\n",
       " 'scared',\n",
       " 'schizophrenia',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seek',\n",
       " 'session',\n",
       " 'shall',\n",
       " 'share',\n",
       " 'should',\n",
       " 'sign',\n",
       " 'sister',\n",
       " 'situation',\n",
       " 'sleep',\n",
       " 'sleeping',\n",
       " 'slot',\n",
       " 'so',\n",
       " 'social',\n",
       " 'someone',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'stage',\n",
       " 'state',\n",
       " 'statistic',\n",
       " 'stress',\n",
       " 'struggle',\n",
       " 'student',\n",
       " 'suffer',\n",
       " 'suicidal',\n",
       " 'symptom',\n",
       " 'talk',\n",
       " 'talking',\n",
       " 'tell',\n",
       " 'test',\n",
       " 'text',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'that',\n",
       " 'the',\n",
       " 'there',\n",
       " 'they',\n",
       " 'thing',\n",
       " 'thought',\n",
       " 'tired',\n",
       " 'tiring',\n",
       " 'to',\n",
       " 'today',\n",
       " 'treat',\n",
       " 'treatment',\n",
       " 'trigger',\n",
       " 'trouble',\n",
       " 'unit',\n",
       " 'use',\n",
       " 'very',\n",
       " 'wa',\n",
       " 'want',\n",
       " 'warning',\n",
       " 'way',\n",
       " 'we',\n",
       " 'well',\n",
       " 'what',\n",
       " 'whatsup',\n",
       " 'when',\n",
       " 'where',\n",
       " 'whether',\n",
       " 'who',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'would',\n",
       " 'wow',\n",
       " 'yeah',\n",
       " 'you',\n",
       " 'your']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create model \n",
    "The model created has 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons equal to number of intents to predict output intent with softmax. \n",
    "\n",
    "This model uses the Keras sequential API for this. After training the model for 200 epochs, we achieved 94% accuracy on the model created. The model is saved as ‘chatbot_model.h5’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "#Define function F1, Precision and Recall\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               80384     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "=================================================================\n",
      "Total params: 121,536\n",
      "Trainable params: 121,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['acc',f1_m,precision_m, recall_m])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 313)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "49/49 [==============================] - 3s 38ms/step - loss: 4.1476 - acc: 0.0352 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 4.0598 - val_acc: 0.0484 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 3.9809 - acc: 0.0838 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 3.9233 - val_acc: 0.1129 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 3/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 3.7175 - acc: 0.1128 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 3.7484 - val_acc: 0.1452 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 4/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 3.4461 - acc: 0.1654 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 3.5464 - val_acc: 0.1452 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 5/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 3.2134 - acc: 0.2234 - f1_m: 0.0149 - precision_m: 0.0440 - recall_m: 0.0090 - val_loss: 3.3306 - val_acc: 0.2258 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 6/400\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 2.8050 - acc: 0.2938 - f1_m: 0.0747 - precision_m: 0.1817 - recall_m: 0.0482 - val_loss: 3.1762 - val_acc: 0.2419 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 7/400\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 2.5970 - acc: 0.3343 - f1_m: 0.1389 - precision_m: 0.3857 - recall_m: 0.0862 - val_loss: 3.0452 - val_acc: 0.2097 - val_f1_m: 0.0256 - val_precision_m: 0.0769 - val_recall_m: 0.0154\n",
      "Epoch 8/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 2.1574 - acc: 0.4303 - f1_m: 0.2522 - precision_m: 0.5249 - recall_m: 0.1710 - val_loss: 2.7742 - val_acc: 0.3226 - val_f1_m: 0.1026 - val_precision_m: 0.3077 - val_recall_m: 0.0615\n",
      "Epoch 9/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 2.2269 - acc: 0.4596 - f1_m: 0.2857 - precision_m: 0.6651 - recall_m: 0.1893 - val_loss: 2.6641 - val_acc: 0.3387 - val_f1_m: 0.1429 - val_precision_m: 0.3462 - val_recall_m: 0.0923\n",
      "Epoch 10/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.8926 - acc: 0.4980 - f1_m: 0.3463 - precision_m: 0.8370 - recall_m: 0.2265 - val_loss: 2.5087 - val_acc: 0.3387 - val_f1_m: 0.1850 - val_precision_m: 0.3077 - val_recall_m: 0.1385\n",
      "Epoch 11/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 1.6820 - acc: 0.5050 - f1_m: 0.3981 - precision_m: 0.7965 - recall_m: 0.2749 - val_loss: 2.4378 - val_acc: 0.3065 - val_f1_m: 0.2106 - val_precision_m: 0.3846 - val_recall_m: 0.1538\n",
      "Epoch 12/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.5596 - acc: 0.5687 - f1_m: 0.4581 - precision_m: 0.8225 - recall_m: 0.3381 - val_loss: 2.3790 - val_acc: 0.4032 - val_f1_m: 0.3059 - val_precision_m: 0.6154 - val_recall_m: 0.2154\n",
      "Epoch 13/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.4395 - acc: 0.5867 - f1_m: 0.5100 - precision_m: 0.8209 - recall_m: 0.3948 - val_loss: 2.3664 - val_acc: 0.3387 - val_f1_m: 0.2372 - val_precision_m: 0.4231 - val_recall_m: 0.1692\n",
      "Epoch 14/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.6503 - acc: 0.4999 - f1_m: 0.4319 - precision_m: 0.7162 - recall_m: 0.3287 - val_loss: 2.3409 - val_acc: 0.4032 - val_f1_m: 0.2711 - val_precision_m: 0.5385 - val_recall_m: 0.1846\n",
      "Epoch 15/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.5390 - acc: 0.5672 - f1_m: 0.4216 - precision_m: 0.6834 - recall_m: 0.3224 - val_loss: 2.3327 - val_acc: 0.3710 - val_f1_m: 0.3294 - val_precision_m: 0.5577 - val_recall_m: 0.2462\n",
      "Epoch 16/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.2264 - acc: 0.5951 - f1_m: 0.5699 - precision_m: 0.8025 - recall_m: 0.4562 - val_loss: 2.1870 - val_acc: 0.4355 - val_f1_m: 0.3425 - val_precision_m: 0.6154 - val_recall_m: 0.2462\n",
      "Epoch 17/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.0375 - acc: 0.7196 - f1_m: 0.5871 - precision_m: 0.8754 - recall_m: 0.4688 - val_loss: 2.2011 - val_acc: 0.4839 - val_f1_m: 0.3507 - val_precision_m: 0.5897 - val_recall_m: 0.2615\n",
      "Epoch 18/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 1.2825 - acc: 0.6081 - f1_m: 0.5525 - precision_m: 0.7148 - recall_m: 0.4641 - val_loss: 2.3087 - val_acc: 0.4677 - val_f1_m: 0.3532 - val_precision_m: 0.6154 - val_recall_m: 0.2615\n",
      "Epoch 19/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.9605 - acc: 0.7249 - f1_m: 0.6609 - precision_m: 0.8458 - recall_m: 0.5711 - val_loss: 2.2857 - val_acc: 0.4677 - val_f1_m: 0.3843 - val_precision_m: 0.5897 - val_recall_m: 0.2923\n",
      "Epoch 20/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.7712 - acc: 0.7839 - f1_m: 0.7723 - precision_m: 0.9045 - recall_m: 0.6972 - val_loss: 2.2490 - val_acc: 0.4355 - val_f1_m: 0.3748 - val_precision_m: 0.5064 - val_recall_m: 0.3077\n",
      "Epoch 21/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.8334 - acc: 0.7492 - f1_m: 0.7017 - precision_m: 0.8341 - recall_m: 0.6185 - val_loss: 2.3433 - val_acc: 0.4516 - val_f1_m: 0.4188 - val_precision_m: 0.5897 - val_recall_m: 0.3385\n",
      "Epoch 22/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.6363 - acc: 0.8118 - f1_m: 0.7863 - precision_m: 0.9131 - recall_m: 0.7037 - val_loss: 2.2614 - val_acc: 0.4032 - val_f1_m: 0.3468 - val_precision_m: 0.5000 - val_recall_m: 0.2769\n",
      "Epoch 23/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8998 - acc: 0.7288 - f1_m: 0.6785 - precision_m: 0.8189 - recall_m: 0.5951 - val_loss: 2.2150 - val_acc: 0.4516 - val_f1_m: 0.4277 - val_precision_m: 0.6026 - val_recall_m: 0.3538\n",
      "Epoch 24/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.6360 - acc: 0.7916 - f1_m: 0.7177 - precision_m: 0.8845 - recall_m: 0.6330 - val_loss: 2.2854 - val_acc: 0.4194 - val_f1_m: 0.4428 - val_precision_m: 0.5615 - val_recall_m: 0.3846\n",
      "Epoch 25/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.8003 - acc: 0.7389 - f1_m: 0.7109 - precision_m: 0.8594 - recall_m: 0.6242 - val_loss: 2.3667 - val_acc: 0.4677 - val_f1_m: 0.3948 - val_precision_m: 0.4962 - val_recall_m: 0.3385\n",
      "Epoch 26/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5558 - acc: 0.8500 - f1_m: 0.8485 - precision_m: 0.9306 - recall_m: 0.7951 - val_loss: 2.4039 - val_acc: 0.4516 - val_f1_m: 0.4053 - val_precision_m: 0.5038 - val_recall_m: 0.3538\n",
      "Epoch 27/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5779 - acc: 0.8282 - f1_m: 0.7978 - precision_m: 0.9020 - recall_m: 0.7341 - val_loss: 2.4756 - val_acc: 0.4516 - val_f1_m: 0.4181 - val_precision_m: 0.5359 - val_recall_m: 0.3538\n",
      "Epoch 28/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.6416 - acc: 0.8075 - f1_m: 0.7856 - precision_m: 0.9160 - recall_m: 0.6992 - val_loss: 2.6286 - val_acc: 0.4355 - val_f1_m: 0.3632 - val_precision_m: 0.4346 - val_recall_m: 0.3231\n",
      "Epoch 29/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5367 - acc: 0.8409 - f1_m: 0.8011 - precision_m: 0.9069 - recall_m: 0.7395 - val_loss: 2.5827 - val_acc: 0.4677 - val_f1_m: 0.3867 - val_precision_m: 0.4731 - val_recall_m: 0.3385\n",
      "Epoch 30/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5838 - acc: 0.8065 - f1_m: 0.7738 - precision_m: 0.9181 - recall_m: 0.6937 - val_loss: 2.6360 - val_acc: 0.4677 - val_f1_m: 0.4449 - val_precision_m: 0.5154 - val_recall_m: 0.4000\n",
      "Epoch 31/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5029 - acc: 0.8475 - f1_m: 0.8432 - precision_m: 0.9283 - recall_m: 0.7801 - val_loss: 2.5327 - val_acc: 0.4516 - val_f1_m: 0.4263 - val_precision_m: 0.4962 - val_recall_m: 0.3846\n",
      "Epoch 32/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 3ms/step - loss: 0.6029 - acc: 0.8108 - f1_m: 0.7663 - precision_m: 0.8541 - recall_m: 0.7071 - val_loss: 2.6242 - val_acc: 0.4677 - val_f1_m: 0.4345 - val_precision_m: 0.5346 - val_recall_m: 0.3846\n",
      "Epoch 33/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5717 - acc: 0.8138 - f1_m: 0.8104 - precision_m: 0.9078 - recall_m: 0.7440 - val_loss: 2.5924 - val_acc: 0.4839 - val_f1_m: 0.4505 - val_precision_m: 0.5821 - val_recall_m: 0.3846\n",
      "Epoch 34/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4518 - acc: 0.8844 - f1_m: 0.8816 - precision_m: 0.9473 - recall_m: 0.8372 - val_loss: 2.5744 - val_acc: 0.4839 - val_f1_m: 0.4556 - val_precision_m: 0.5154 - val_recall_m: 0.4154\n",
      "Epoch 35/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4918 - acc: 0.8858 - f1_m: 0.8426 - precision_m: 0.9474 - recall_m: 0.7845 - val_loss: 2.4942 - val_acc: 0.4839 - val_f1_m: 0.4269 - val_precision_m: 0.5282 - val_recall_m: 0.3692\n",
      "Epoch 36/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3836 - acc: 0.9083 - f1_m: 0.8620 - precision_m: 0.9619 - recall_m: 0.7988 - val_loss: 2.7291 - val_acc: 0.4839 - val_f1_m: 0.4346 - val_precision_m: 0.5115 - val_recall_m: 0.3846\n",
      "Epoch 37/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.5192 - acc: 0.8091 - f1_m: 0.8166 - precision_m: 0.9000 - recall_m: 0.7587 - val_loss: 2.6801 - val_acc: 0.4839 - val_f1_m: 0.4615 - val_precision_m: 0.5321 - val_recall_m: 0.4154\n",
      "Epoch 38/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4261 - acc: 0.8976 - f1_m: 0.9035 - precision_m: 0.9702 - recall_m: 0.8652 - val_loss: 2.7200 - val_acc: 0.4839 - val_f1_m: 0.4374 - val_precision_m: 0.4987 - val_recall_m: 0.4000\n",
      "Epoch 39/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4885 - acc: 0.8797 - f1_m: 0.8724 - precision_m: 0.9523 - recall_m: 0.8236 - val_loss: 2.7296 - val_acc: 0.5000 - val_f1_m: 0.4970 - val_precision_m: 0.5782 - val_recall_m: 0.4462\n",
      "Epoch 40/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3266 - acc: 0.8868 - f1_m: 0.8740 - precision_m: 0.9184 - recall_m: 0.8419 - val_loss: 2.7622 - val_acc: 0.4677 - val_f1_m: 0.4341 - val_precision_m: 0.5205 - val_recall_m: 0.3846\n",
      "Epoch 41/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3086 - acc: 0.9180 - f1_m: 0.9064 - precision_m: 0.9448 - recall_m: 0.8801 - val_loss: 2.8595 - val_acc: 0.4677 - val_f1_m: 0.4423 - val_precision_m: 0.5064 - val_recall_m: 0.4000\n",
      "Epoch 42/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3755 - acc: 0.8846 - f1_m: 0.8840 - precision_m: 0.9408 - recall_m: 0.8434 - val_loss: 2.8518 - val_acc: 0.4516 - val_f1_m: 0.4373 - val_precision_m: 0.5359 - val_recall_m: 0.3846\n",
      "Epoch 43/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2567 - acc: 0.9075 - f1_m: 0.8969 - precision_m: 0.9423 - recall_m: 0.8678 - val_loss: 2.9801 - val_acc: 0.4516 - val_f1_m: 0.4470 - val_precision_m: 0.4962 - val_recall_m: 0.4154\n",
      "Epoch 44/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.4184 - acc: 0.8533 - f1_m: 0.8743 - precision_m: 0.9336 - recall_m: 0.8313 - val_loss: 2.9369 - val_acc: 0.4677 - val_f1_m: 0.4781 - val_precision_m: 0.5346 - val_recall_m: 0.4462\n",
      "Epoch 45/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2909 - acc: 0.9169 - f1_m: 0.8753 - precision_m: 0.9483 - recall_m: 0.8307 - val_loss: 3.1070 - val_acc: 0.4516 - val_f1_m: 0.4205 - val_precision_m: 0.4718 - val_recall_m: 0.3846\n",
      "Epoch 46/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2509 - acc: 0.9323 - f1_m: 0.9302 - precision_m: 0.9520 - recall_m: 0.9130 - val_loss: 3.1110 - val_acc: 0.4355 - val_f1_m: 0.4338 - val_precision_m: 0.4808 - val_recall_m: 0.4000\n",
      "Epoch 47/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3500 - acc: 0.9079 - f1_m: 0.8956 - precision_m: 0.9209 - recall_m: 0.8767 - val_loss: 2.9365 - val_acc: 0.4516 - val_f1_m: 0.4291 - val_precision_m: 0.4974 - val_recall_m: 0.3846\n",
      "Epoch 48/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3028 - acc: 0.9261 - f1_m: 0.8960 - precision_m: 0.9576 - recall_m: 0.8558 - val_loss: 2.9179 - val_acc: 0.5161 - val_f1_m: 0.4829 - val_precision_m: 0.5897 - val_recall_m: 0.4154\n",
      "Epoch 49/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.3480 - acc: 0.8699 - f1_m: 0.8677 - precision_m: 0.9207 - recall_m: 0.8295 - val_loss: 3.0169 - val_acc: 0.4839 - val_f1_m: 0.4612 - val_precision_m: 0.5513 - val_recall_m: 0.4154\n",
      "Epoch 50/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3227 - acc: 0.9093 - f1_m: 0.8811 - precision_m: 0.9384 - recall_m: 0.8418 - val_loss: 2.9717 - val_acc: 0.4839 - val_f1_m: 0.4671 - val_precision_m: 0.5205 - val_recall_m: 0.4308\n",
      "Epoch 51/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2655 - acc: 0.9251 - f1_m: 0.9337 - precision_m: 0.9744 - recall_m: 0.9019 - val_loss: 2.9486 - val_acc: 0.5000 - val_f1_m: 0.4932 - val_precision_m: 0.5423 - val_recall_m: 0.4615\n",
      "Epoch 52/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2945 - acc: 0.9214 - f1_m: 0.9113 - precision_m: 0.9416 - recall_m: 0.8874 - val_loss: 3.1287 - val_acc: 0.5000 - val_f1_m: 0.4542 - val_precision_m: 0.5449 - val_recall_m: 0.4000\n",
      "Epoch 53/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2860 - acc: 0.9158 - f1_m: 0.9168 - precision_m: 0.9429 - recall_m: 0.8968 - val_loss: 3.1616 - val_acc: 0.4516 - val_f1_m: 0.4389 - val_precision_m: 0.4987 - val_recall_m: 0.4000\n",
      "Epoch 54/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.3461 - acc: 0.8862 - f1_m: 0.8906 - precision_m: 0.9514 - recall_m: 0.8471 - val_loss: 2.9951 - val_acc: 0.5000 - val_f1_m: 0.4679 - val_precision_m: 0.5256 - val_recall_m: 0.4308\n",
      "Epoch 55/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2429 - acc: 0.9329 - f1_m: 0.9027 - precision_m: 0.9468 - recall_m: 0.8744 - val_loss: 3.1285 - val_acc: 0.4839 - val_f1_m: 0.4868 - val_precision_m: 0.5423 - val_recall_m: 0.4462\n",
      "Epoch 56/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2584 - acc: 0.9144 - f1_m: 0.8932 - precision_m: 0.9382 - recall_m: 0.8572 - val_loss: 3.1490 - val_acc: 0.4516 - val_f1_m: 0.4214 - val_precision_m: 0.4769 - val_recall_m: 0.3846\n",
      "Epoch 57/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2394 - acc: 0.9216 - f1_m: 0.9061 - precision_m: 0.9476 - recall_m: 0.8772 - val_loss: 3.1544 - val_acc: 0.5000 - val_f1_m: 0.4952 - val_precision_m: 0.5538 - val_recall_m: 0.4615\n",
      "Epoch 58/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1795 - acc: 0.9465 - f1_m: 0.9341 - precision_m: 0.9594 - recall_m: 0.9138 - val_loss: 3.0111 - val_acc: 0.4839 - val_f1_m: 0.4526 - val_precision_m: 0.5103 - val_recall_m: 0.4154\n",
      "Epoch 59/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1790 - acc: 0.9436 - f1_m: 0.9485 - precision_m: 0.9660 - recall_m: 0.9345 - val_loss: 3.1145 - val_acc: 0.4677 - val_f1_m: 0.4924 - val_precision_m: 0.6038 - val_recall_m: 0.4308\n",
      "Epoch 60/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2035 - acc: 0.9517 - f1_m: 0.9348 - precision_m: 0.9646 - recall_m: 0.9109 - val_loss: 3.1111 - val_acc: 0.5000 - val_f1_m: 0.4940 - val_precision_m: 0.5987 - val_recall_m: 0.4462\n",
      "Epoch 61/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1921 - acc: 0.9366 - f1_m: 0.9351 - precision_m: 0.9595 - recall_m: 0.9162 - val_loss: 3.1263 - val_acc: 0.5161 - val_f1_m: 0.4970 - val_precision_m: 0.5526 - val_recall_m: 0.4615\n",
      "Epoch 62/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2498 - acc: 0.9361 - f1_m: 0.9213 - precision_m: 0.9403 - recall_m: 0.9061 - val_loss: 3.1600 - val_acc: 0.5000 - val_f1_m: 0.4611 - val_precision_m: 0.5359 - val_recall_m: 0.4154\n",
      "Epoch 63/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2378 - acc: 0.9160 - f1_m: 0.9088 - precision_m: 0.9499 - recall_m: 0.8774 - val_loss: 3.0144 - val_acc: 0.4839 - val_f1_m: 0.4799 - val_precision_m: 0.5269 - val_recall_m: 0.4462\n",
      "Epoch 64/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2325 - acc: 0.9364 - f1_m: 0.9217 - precision_m: 0.9535 - recall_m: 0.8962 - val_loss: 3.1147 - val_acc: 0.4677 - val_f1_m: 0.4474 - val_precision_m: 0.4923 - val_recall_m: 0.4154\n",
      "Epoch 65/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1674 - acc: 0.9559 - f1_m: 0.9480 - precision_m: 0.9702 - recall_m: 0.9311 - val_loss: 3.2689 - val_acc: 0.4355 - val_f1_m: 0.4264 - val_precision_m: 0.5000 - val_recall_m: 0.3846\n",
      "Epoch 66/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1875 - acc: 0.9432 - f1_m: 0.9434 - precision_m: 0.9818 - recall_m: 0.9127 - val_loss: 3.2039 - val_acc: 0.4516 - val_f1_m: 0.4489 - val_precision_m: 0.5038 - val_recall_m: 0.4154\n",
      "Epoch 67/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2048 - acc: 0.9645 - f1_m: 0.9272 - precision_m: 0.9701 - recall_m: 0.8937 - val_loss: 3.1958 - val_acc: 0.4677 - val_f1_m: 0.4350 - val_precision_m: 0.5077 - val_recall_m: 0.3846\n",
      "Epoch 68/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1104 - acc: 0.9700 - f1_m: 0.9647 - precision_m: 0.9781 - recall_m: 0.9539 - val_loss: 3.1088 - val_acc: 0.5000 - val_f1_m: 0.4875 - val_precision_m: 0.5590 - val_recall_m: 0.4462\n",
      "Epoch 69/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1962 - acc: 0.9504 - f1_m: 0.9304 - precision_m: 0.9544 - recall_m: 0.9137 - val_loss: 3.1199 - val_acc: 0.5000 - val_f1_m: 0.5006 - val_precision_m: 0.6282 - val_recall_m: 0.4462\n",
      "Epoch 70/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1528 - acc: 0.9534 - f1_m: 0.9442 - precision_m: 0.9671 - recall_m: 0.9261 - val_loss: 3.2242 - val_acc: 0.5161 - val_f1_m: 0.4833 - val_precision_m: 0.5731 - val_recall_m: 0.4462\n",
      "Epoch 71/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1521 - acc: 0.9645 - f1_m: 0.9511 - precision_m: 0.9696 - recall_m: 0.9374 - val_loss: 3.2156 - val_acc: 0.5000 - val_f1_m: 0.4962 - val_precision_m: 0.5474 - val_recall_m: 0.4615\n",
      "Epoch 72/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1565 - acc: 0.9590 - f1_m: 0.9522 - precision_m: 0.9832 - recall_m: 0.9275 - val_loss: 3.2567 - val_acc: 0.5161 - val_f1_m: 0.5109 - val_precision_m: 0.5679 - val_recall_m: 0.4769\n",
      "Epoch 73/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1517 - acc: 0.9588 - f1_m: 0.9471 - precision_m: 0.9658 - recall_m: 0.9323 - val_loss: 3.2848 - val_acc: 0.5161 - val_f1_m: 0.4848 - val_precision_m: 0.5462 - val_recall_m: 0.4462\n",
      "Epoch 74/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2281 - acc: 0.9226 - f1_m: 0.9195 - precision_m: 0.9227 - recall_m: 0.9170 - val_loss: 3.2980 - val_acc: 0.4839 - val_f1_m: 0.4583 - val_precision_m: 0.5282 - val_recall_m: 0.4154\n",
      "Epoch 75/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2009 - acc: 0.9195 - f1_m: 0.9185 - precision_m: 0.9528 - recall_m: 0.8916 - val_loss: 3.3003 - val_acc: 0.5000 - val_f1_m: 0.4600 - val_precision_m: 0.5321 - val_recall_m: 0.4154\n",
      "Epoch 76/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2999 - acc: 0.9153 - f1_m: 0.9036 - precision_m: 0.9270 - recall_m: 0.8872 - val_loss: 3.3652 - val_acc: 0.5161 - val_f1_m: 0.4677 - val_precision_m: 0.5269 - val_recall_m: 0.4308\n",
      "Epoch 77/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1426 - acc: 0.9625 - f1_m: 0.9508 - precision_m: 0.9672 - recall_m: 0.9377 - val_loss: 3.4155 - val_acc: 0.4516 - val_f1_m: 0.4321 - val_precision_m: 0.4769 - val_recall_m: 0.4000\n",
      "Epoch 78/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1079 - acc: 0.9732 - f1_m: 0.9568 - precision_m: 0.9777 - recall_m: 0.9401 - val_loss: 3.5431 - val_acc: 0.4839 - val_f1_m: 0.4574 - val_precision_m: 0.5231 - val_recall_m: 0.4154\n",
      "Epoch 79/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2357 - acc: 0.8920 - f1_m: 0.8934 - precision_m: 0.9149 - recall_m: 0.8779 - val_loss: 3.5776 - val_acc: 0.4677 - val_f1_m: 0.4440 - val_precision_m: 0.5038 - val_recall_m: 0.4000\n",
      "Epoch 80/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1684 - acc: 0.9369 - f1_m: 0.9385 - precision_m: 0.9531 - recall_m: 0.9268 - val_loss: 3.5069 - val_acc: 0.4839 - val_f1_m: 0.4333 - val_precision_m: 0.5423 - val_recall_m: 0.3846\n",
      "Epoch 81/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1444 - acc: 0.9447 - f1_m: 0.9287 - precision_m: 0.9548 - recall_m: 0.9078 - val_loss: 3.4537 - val_acc: 0.5000 - val_f1_m: 0.4747 - val_precision_m: 0.5462 - val_recall_m: 0.4308\n",
      "Epoch 82/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1524 - acc: 0.9539 - f1_m: 0.9435 - precision_m: 0.9547 - recall_m: 0.9346 - val_loss: 3.5496 - val_acc: 0.4677 - val_f1_m: 0.4395 - val_precision_m: 0.5051 - val_recall_m: 0.4000\n",
      "Epoch 83/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1090 - acc: 0.9519 - f1_m: 0.9533 - precision_m: 0.9642 - recall_m: 0.9445 - val_loss: 3.5147 - val_acc: 0.4677 - val_f1_m: 0.4406 - val_precision_m: 0.5026 - val_recall_m: 0.4000\n",
      "Epoch 84/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1864 - acc: 0.9361 - f1_m: 0.9245 - precision_m: 0.9428 - recall_m: 0.9106 - val_loss: 3.6313 - val_acc: 0.4355 - val_f1_m: 0.4214 - val_precision_m: 0.4769 - val_recall_m: 0.3846\n",
      "Epoch 85/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1670 - acc: 0.9595 - f1_m: 0.9507 - precision_m: 0.9612 - recall_m: 0.9422 - val_loss: 3.6610 - val_acc: 0.4355 - val_f1_m: 0.4291 - val_precision_m: 0.4718 - val_recall_m: 0.4000\n",
      "Epoch 86/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.2144 - acc: 0.9427 - f1_m: 0.9355 - precision_m: 0.9438 - recall_m: 0.9291 - val_loss: 3.9399 - val_acc: 0.4355 - val_f1_m: 0.4419 - val_precision_m: 0.4782 - val_recall_m: 0.4154\n",
      "Epoch 87/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1889 - acc: 0.9417 - f1_m: 0.9275 - precision_m: 0.9586 - recall_m: 0.9026 - val_loss: 3.7559 - val_acc: 0.4516 - val_f1_m: 0.4560 - val_precision_m: 0.4923 - val_recall_m: 0.4308\n",
      "Epoch 88/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1255 - acc: 0.9603 - f1_m: 0.9578 - precision_m: 0.9768 - recall_m: 0.9427 - val_loss: 3.6969 - val_acc: 0.4677 - val_f1_m: 0.4705 - val_precision_m: 0.5282 - val_recall_m: 0.4308\n",
      "Epoch 89/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1831 - acc: 0.9612 - f1_m: 0.9658 - precision_m: 0.9760 - recall_m: 0.9575 - val_loss: 3.7541 - val_acc: 0.4677 - val_f1_m: 0.4645 - val_precision_m: 0.5372 - val_recall_m: 0.4154\n",
      "Epoch 90/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1207 - acc: 0.9622 - f1_m: 0.9635 - precision_m: 0.9721 - recall_m: 0.9577 - val_loss: 3.6359 - val_acc: 0.4516 - val_f1_m: 0.4543 - val_precision_m: 0.5141 - val_recall_m: 0.4154\n",
      "Epoch 91/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1024 - acc: 0.9847 - f1_m: 0.9823 - precision_m: 0.9935 - recall_m: 0.9734 - val_loss: 3.6251 - val_acc: 0.4516 - val_f1_m: 0.4502 - val_precision_m: 0.5115 - val_recall_m: 0.4154\n",
      "Epoch 92/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1723 - acc: 0.9381 - f1_m: 0.9280 - precision_m: 0.9532 - recall_m: 0.9083 - val_loss: 3.7335 - val_acc: 0.4355 - val_f1_m: 0.4312 - val_precision_m: 0.4782 - val_recall_m: 0.4000\n",
      "Epoch 93/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1380 - acc: 0.9579 - f1_m: 0.9609 - precision_m: 0.9728 - recall_m: 0.9514 - val_loss: 3.6287 - val_acc: 0.4677 - val_f1_m: 0.4623 - val_precision_m: 0.5423 - val_recall_m: 0.4154\n",
      "Epoch 94/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1527 - acc: 0.9274 - f1_m: 0.9430 - precision_m: 0.9642 - recall_m: 0.9263 - val_loss: 3.6370 - val_acc: 0.4677 - val_f1_m: 0.4421 - val_precision_m: 0.5141 - val_recall_m: 0.4000\n",
      "Epoch 95/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1689 - acc: 0.9303 - f1_m: 0.9259 - precision_m: 0.9348 - recall_m: 0.9187 - val_loss: 3.6742 - val_acc: 0.4355 - val_f1_m: 0.4363 - val_precision_m: 0.4897 - val_recall_m: 0.4000\n",
      "Epoch 96/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1283 - acc: 0.9702 - f1_m: 0.9599 - precision_m: 0.9743 - recall_m: 0.9489 - val_loss: 3.6507 - val_acc: 0.4355 - val_f1_m: 0.4496 - val_precision_m: 0.5051 - val_recall_m: 0.4154\n",
      "Epoch 97/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1551 - acc: 0.9293 - f1_m: 0.9347 - precision_m: 0.9653 - recall_m: 0.9102 - val_loss: 3.7455 - val_acc: 0.4516 - val_f1_m: 0.4534 - val_precision_m: 0.5410 - val_recall_m: 0.4154\n",
      "Epoch 98/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1019 - acc: 0.9651 - f1_m: 0.9623 - precision_m: 0.9741 - recall_m: 0.9528 - val_loss: 3.6459 - val_acc: 0.4839 - val_f1_m: 0.4613 - val_precision_m: 0.5141 - val_recall_m: 0.4308\n",
      "Epoch 99/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1025 - acc: 0.9782 - f1_m: 0.9814 - precision_m: 0.9979 - recall_m: 0.9682 - val_loss: 3.6540 - val_acc: 0.5000 - val_f1_m: 0.4855 - val_precision_m: 0.5218 - val_recall_m: 0.4615\n",
      "Epoch 100/400\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1287 - acc: 0.9547 - f1_m: 0.9526 - precision_m: 0.9753 - recall_m: 0.9345 - val_loss: 3.7241 - val_acc: 0.4839 - val_f1_m: 0.4651 - val_precision_m: 0.5244 - val_recall_m: 0.4308\n",
      "Epoch 101/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.2871 - acc: 0.9231 - f1_m: 0.9143 - precision_m: 0.9338 - recall_m: 0.8988 - val_loss: 3.8354 - val_acc: 0.4839 - val_f1_m: 0.4653 - val_precision_m: 0.5282 - val_recall_m: 0.4308\n",
      "Epoch 102/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1380 - acc: 0.9603 - f1_m: 0.9551 - precision_m: 0.9721 - recall_m: 0.9415 - val_loss: 3.8232 - val_acc: 0.4677 - val_f1_m: 0.4774 - val_precision_m: 0.5244 - val_recall_m: 0.4462\n",
      "Epoch 103/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1141 - acc: 0.9550 - f1_m: 0.9487 - precision_m: 0.9737 - recall_m: 0.9287 - val_loss: 3.8230 - val_acc: 0.4516 - val_f1_m: 0.4500 - val_precision_m: 0.4821 - val_recall_m: 0.4308\n",
      "Epoch 104/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1761 - acc: 0.9440 - f1_m: 0.9336 - precision_m: 0.9546 - recall_m: 0.9187 - val_loss: 3.7554 - val_acc: 0.4839 - val_f1_m: 0.4731 - val_precision_m: 0.5179 - val_recall_m: 0.4462\n",
      "Epoch 105/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1325 - acc: 0.9595 - f1_m: 0.9512 - precision_m: 0.9638 - recall_m: 0.9423 - val_loss: 3.8194 - val_acc: 0.4839 - val_f1_m: 0.4919 - val_precision_m: 0.5410 - val_recall_m: 0.4615\n",
      "Epoch 106/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1716 - acc: 0.9304 - f1_m: 0.9394 - precision_m: 0.9629 - recall_m: 0.9207 - val_loss: 3.8527 - val_acc: 0.4355 - val_f1_m: 0.4474 - val_precision_m: 0.5103 - val_recall_m: 0.4154\n",
      "Epoch 107/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1452 - acc: 0.9322 - f1_m: 0.9470 - precision_m: 0.9758 - recall_m: 0.9240 - val_loss: 3.8543 - val_acc: 0.5161 - val_f1_m: 0.5103 - val_precision_m: 0.5615 - val_recall_m: 0.4769\n",
      "Epoch 108/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0737 - acc: 0.9764 - f1_m: 0.9748 - precision_m: 0.9813 - recall_m: 0.9696 - val_loss: 3.8316 - val_acc: 0.5000 - val_f1_m: 0.5120 - val_precision_m: 0.5654 - val_recall_m: 0.4769\n",
      "Epoch 109/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0844 - acc: 0.9793 - f1_m: 0.9665 - precision_m: 0.9808 - recall_m: 0.9550 - val_loss: 3.8723 - val_acc: 0.4677 - val_f1_m: 0.4632 - val_precision_m: 0.5282 - val_recall_m: 0.4308\n",
      "Epoch 110/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1744 - acc: 0.9265 - f1_m: 0.9318 - precision_m: 0.9517 - recall_m: 0.9159 - val_loss: 3.8338 - val_acc: 0.4839 - val_f1_m: 0.5059 - val_precision_m: 0.5859 - val_recall_m: 0.4615\n",
      "Epoch 111/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1265 - acc: 0.9625 - f1_m: 0.9563 - precision_m: 0.9692 - recall_m: 0.9459 - val_loss: 3.8180 - val_acc: 0.5323 - val_f1_m: 0.4915 - val_precision_m: 0.5321 - val_recall_m: 0.4615\n",
      "Epoch 112/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0746 - acc: 0.9759 - f1_m: 0.9760 - precision_m: 0.9899 - recall_m: 0.9649 - val_loss: 3.9064 - val_acc: 0.5161 - val_f1_m: 0.5004 - val_precision_m: 0.5346 - val_recall_m: 0.4769\n",
      "Epoch 113/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1216 - acc: 0.9472 - f1_m: 0.9471 - precision_m: 0.9520 - recall_m: 0.9432 - val_loss: 3.9260 - val_acc: 0.4839 - val_f1_m: 0.4688 - val_precision_m: 0.4987 - val_recall_m: 0.4462\n",
      "Epoch 114/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0994 - acc: 0.9783 - f1_m: 0.9781 - precision_m: 0.9845 - recall_m: 0.9730 - val_loss: 4.1085 - val_acc: 0.4839 - val_f1_m: 0.4855 - val_precision_m: 0.5410 - val_recall_m: 0.4462\n",
      "Epoch 115/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0994 - acc: 0.9692 - f1_m: 0.9719 - precision_m: 0.9768 - recall_m: 0.9681 - val_loss: 3.9268 - val_acc: 0.5000 - val_f1_m: 0.5090 - val_precision_m: 0.5538 - val_recall_m: 0.4769\n",
      "Epoch 116/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1532 - acc: 0.9686 - f1_m: 0.9563 - precision_m: 0.9678 - recall_m: 0.9472 - val_loss: 3.9616 - val_acc: 0.4677 - val_f1_m: 0.4701 - val_precision_m: 0.5064 - val_recall_m: 0.4462\n",
      "Epoch 117/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0853 - acc: 0.9645 - f1_m: 0.9649 - precision_m: 0.9760 - recall_m: 0.9561 - val_loss: 3.8555 - val_acc: 0.4839 - val_f1_m: 0.4812 - val_precision_m: 0.5090 - val_recall_m: 0.4615\n",
      "Epoch 118/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1345 - acc: 0.9654 - f1_m: 0.9525 - precision_m: 0.9626 - recall_m: 0.9445 - val_loss: 3.9329 - val_acc: 0.4839 - val_f1_m: 0.4850 - val_precision_m: 0.5192 - val_recall_m: 0.4615\n",
      "Epoch 119/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0827 - acc: 0.9700 - f1_m: 0.9649 - precision_m: 0.9708 - recall_m: 0.9602 - val_loss: 3.9463 - val_acc: 0.5000 - val_f1_m: 0.4936 - val_precision_m: 0.5192 - val_recall_m: 0.4769\n",
      "Epoch 120/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0953 - acc: 0.9512 - f1_m: 0.9583 - precision_m: 0.9713 - recall_m: 0.9479 - val_loss: 3.8746 - val_acc: 0.5000 - val_f1_m: 0.4966 - val_precision_m: 0.5244 - val_recall_m: 0.4769\n",
      "Epoch 121/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0836 - acc: 0.9857 - f1_m: 0.9857 - precision_m: 0.9857 - recall_m: 0.9857 - val_loss: 3.9121 - val_acc: 0.5161 - val_f1_m: 0.5201 - val_precision_m: 0.5628 - val_recall_m: 0.4923\n",
      "Epoch 122/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1323 - acc: 0.9473 - f1_m: 0.9396 - precision_m: 0.9499 - recall_m: 0.9313 - val_loss: 3.9986 - val_acc: 0.4839 - val_f1_m: 0.4816 - val_precision_m: 0.5115 - val_recall_m: 0.4615\n",
      "Epoch 123/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0912 - acc: 0.9614 - f1_m: 0.9587 - precision_m: 0.9614 - recall_m: 0.9565 - val_loss: 4.0164 - val_acc: 0.4839 - val_f1_m: 0.4816 - val_precision_m: 0.5115 - val_recall_m: 0.4615\n",
      "Epoch 124/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0921 - acc: 0.9734 - f1_m: 0.9668 - precision_m: 0.9784 - recall_m: 0.9576 - val_loss: 4.0167 - val_acc: 0.4677 - val_f1_m: 0.4679 - val_precision_m: 0.5000 - val_recall_m: 0.4462\n",
      "Epoch 125/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1347 - acc: 0.9490 - f1_m: 0.9476 - precision_m: 0.9549 - recall_m: 0.9418 - val_loss: 4.0823 - val_acc: 0.4677 - val_f1_m: 0.4645 - val_precision_m: 0.4923 - val_recall_m: 0.4462\n",
      "Epoch 126/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1134 - acc: 0.9435 - f1_m: 0.9516 - precision_m: 0.9730 - recall_m: 0.9344 - val_loss: 4.0215 - val_acc: 0.4677 - val_f1_m: 0.4581 - val_precision_m: 0.4731 - val_recall_m: 0.4462\n",
      "Epoch 127/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1064 - acc: 0.9590 - f1_m: 0.9644 - precision_m: 0.9710 - recall_m: 0.9590 - val_loss: 3.8915 - val_acc: 0.4839 - val_f1_m: 0.4821 - val_precision_m: 0.5141 - val_recall_m: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1185 - acc: 0.9596 - f1_m: 0.9689 - precision_m: 0.9805 - recall_m: 0.9596 - val_loss: 3.9857 - val_acc: 0.4677 - val_f1_m: 0.4624 - val_precision_m: 0.4859 - val_recall_m: 0.4462\n",
      "Epoch 129/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0832 - acc: 0.9729 - f1_m: 0.9683 - precision_m: 0.9770 - recall_m: 0.9615 - val_loss: 3.9905 - val_acc: 0.4677 - val_f1_m: 0.4752 - val_precision_m: 0.5179 - val_recall_m: 0.4462\n",
      "Epoch 130/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1119 - acc: 0.9434 - f1_m: 0.9622 - precision_m: 0.9882 - recall_m: 0.9414 - val_loss: 3.9228 - val_acc: 0.4839 - val_f1_m: 0.4812 - val_precision_m: 0.5282 - val_recall_m: 0.4462\n",
      "Epoch 131/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1068 - acc: 0.9537 - f1_m: 0.9609 - precision_m: 0.9726 - recall_m: 0.9516 - val_loss: 3.8742 - val_acc: 0.5000 - val_f1_m: 0.4957 - val_precision_m: 0.5449 - val_recall_m: 0.4615\n",
      "Epoch 132/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1241 - acc: 0.9424 - f1_m: 0.9417 - precision_m: 0.9503 - recall_m: 0.9348 - val_loss: 3.9295 - val_acc: 0.5161 - val_f1_m: 0.5184 - val_precision_m: 0.5782 - val_recall_m: 0.4769\n",
      "Epoch 133/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0600 - acc: 0.9834 - f1_m: 0.9865 - precision_m: 0.9905 - recall_m: 0.9834 - val_loss: 3.9768 - val_acc: 0.4839 - val_f1_m: 0.5013 - val_precision_m: 0.5590 - val_recall_m: 0.4615\n",
      "Epoch 134/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0851 - acc: 0.9667 - f1_m: 0.9703 - precision_m: 0.9749 - recall_m: 0.9667 - val_loss: 4.0079 - val_acc: 0.4677 - val_f1_m: 0.4500 - val_precision_m: 0.5013 - val_recall_m: 0.4154\n",
      "Epoch 135/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0983 - acc: 0.9568 - f1_m: 0.9553 - precision_m: 0.9568 - recall_m: 0.9540 - val_loss: 3.8672 - val_acc: 0.4839 - val_f1_m: 0.4556 - val_precision_m: 0.4962 - val_recall_m: 0.4308\n",
      "Epoch 136/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0899 - acc: 0.9697 - f1_m: 0.9707 - precision_m: 0.9893 - recall_m: 0.9557 - val_loss: 3.8231 - val_acc: 0.5000 - val_f1_m: 0.4645 - val_precision_m: 0.5179 - val_recall_m: 0.4308\n",
      "Epoch 137/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0848 - acc: 0.9728 - f1_m: 0.9685 - precision_m: 0.9743 - recall_m: 0.9639 - val_loss: 3.8277 - val_acc: 0.4839 - val_f1_m: 0.4701 - val_precision_m: 0.5064 - val_recall_m: 0.4462\n",
      "Epoch 138/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0503 - acc: 0.9776 - f1_m: 0.9778 - precision_m: 0.9779 - recall_m: 0.9776 - val_loss: 3.8739 - val_acc: 0.5000 - val_f1_m: 0.4675 - val_precision_m: 0.5231 - val_recall_m: 0.4308\n",
      "Epoch 139/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0850 - acc: 0.9599 - f1_m: 0.9581 - precision_m: 0.9671 - recall_m: 0.9510 - val_loss: 3.8980 - val_acc: 0.5000 - val_f1_m: 0.4949 - val_precision_m: 0.5205 - val_recall_m: 0.4769\n",
      "Epoch 140/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0667 - acc: 0.9718 - f1_m: 0.9691 - precision_m: 0.9718 - recall_m: 0.9669 - val_loss: 3.9691 - val_acc: 0.4839 - val_f1_m: 0.4735 - val_precision_m: 0.4885 - val_recall_m: 0.4615\n",
      "Epoch 141/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0775 - acc: 0.9694 - f1_m: 0.9625 - precision_m: 0.9709 - recall_m: 0.9558 - val_loss: 3.9255 - val_acc: 0.4677 - val_f1_m: 0.4547 - val_precision_m: 0.4654 - val_recall_m: 0.4462\n",
      "Epoch 142/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0917 - acc: 0.9576 - f1_m: 0.9489 - precision_m: 0.9610 - recall_m: 0.9393 - val_loss: 3.9445 - val_acc: 0.4839 - val_f1_m: 0.4564 - val_precision_m: 0.4692 - val_recall_m: 0.4462\n",
      "Epoch 143/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1096 - acc: 0.9377 - f1_m: 0.9298 - precision_m: 0.9381 - recall_m: 0.9231 - val_loss: 4.0671 - val_acc: 0.4839 - val_f1_m: 0.4769 - val_precision_m: 0.4962 - val_recall_m: 0.4615\n",
      "Epoch 144/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1010 - acc: 0.9720 - f1_m: 0.9768 - precision_m: 0.9827 - recall_m: 0.9720 - val_loss: 3.9980 - val_acc: 0.4677 - val_f1_m: 0.4530 - val_precision_m: 0.4872 - val_recall_m: 0.4308\n",
      "Epoch 145/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0810 - acc: 0.9780 - f1_m: 0.9775 - precision_m: 0.9780 - recall_m: 0.9771 - val_loss: 3.9988 - val_acc: 0.4677 - val_f1_m: 0.4615 - val_precision_m: 0.4808 - val_recall_m: 0.4462\n",
      "Epoch 146/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1351 - acc: 0.9667 - f1_m: 0.9519 - precision_m: 0.9632 - recall_m: 0.9429 - val_loss: 4.0545 - val_acc: 0.4839 - val_f1_m: 0.4829 - val_precision_m: 0.5128 - val_recall_m: 0.4615\n",
      "Epoch 147/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0795 - acc: 0.9881 - f1_m: 0.9879 - precision_m: 0.9905 - recall_m: 0.9858 - val_loss: 4.1329 - val_acc: 0.4839 - val_f1_m: 0.4624 - val_precision_m: 0.4859 - val_recall_m: 0.4462\n",
      "Epoch 148/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1248 - acc: 0.9582 - f1_m: 0.9582 - precision_m: 0.9582 - recall_m: 0.9582 - val_loss: 4.1193 - val_acc: 0.4677 - val_f1_m: 0.4679 - val_precision_m: 0.5115 - val_recall_m: 0.4462\n",
      "Epoch 149/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0868 - acc: 0.9682 - f1_m: 0.9697 - precision_m: 0.9716 - recall_m: 0.9682 - val_loss: 4.1083 - val_acc: 0.5000 - val_f1_m: 0.4850 - val_precision_m: 0.5308 - val_recall_m: 0.4615\n",
      "Epoch 150/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0896 - acc: 0.9622 - f1_m: 0.9609 - precision_m: 0.9633 - recall_m: 0.9590 - val_loss: 4.0393 - val_acc: 0.4839 - val_f1_m: 0.4667 - val_precision_m: 0.4923 - val_recall_m: 0.4462\n",
      "Epoch 151/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1131 - acc: 0.9539 - f1_m: 0.9498 - precision_m: 0.9548 - recall_m: 0.9457 - val_loss: 4.0314 - val_acc: 0.4839 - val_f1_m: 0.4551 - val_precision_m: 0.4872 - val_recall_m: 0.4308\n",
      "Epoch 152/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0739 - acc: 0.9707 - f1_m: 0.9688 - precision_m: 0.9759 - recall_m: 0.9630 - val_loss: 4.1229 - val_acc: 0.4839 - val_f1_m: 0.4564 - val_precision_m: 0.4949 - val_recall_m: 0.4308\n",
      "Epoch 153/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0935 - acc: 0.9470 - f1_m: 0.9500 - precision_m: 0.9595 - recall_m: 0.9439 - val_loss: 4.2123 - val_acc: 0.4677 - val_f1_m: 0.4667 - val_precision_m: 0.4923 - val_recall_m: 0.4462\n",
      "Epoch 154/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1114 - acc: 0.9601 - f1_m: 0.9497 - precision_m: 0.9627 - recall_m: 0.9396 - val_loss: 4.1074 - val_acc: 0.4839 - val_f1_m: 0.4675 - val_precision_m: 0.4974 - val_recall_m: 0.4462\n",
      "Epoch 155/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0614 - acc: 0.9595 - f1_m: 0.9641 - precision_m: 0.9716 - recall_m: 0.9581 - val_loss: 4.1188 - val_acc: 0.4677 - val_f1_m: 0.4658 - val_precision_m: 0.4936 - val_recall_m: 0.4462\n",
      "Epoch 156/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1205 - acc: 0.9487 - f1_m: 0.9458 - precision_m: 0.9487 - recall_m: 0.9435 - val_loss: 4.1127 - val_acc: 0.4677 - val_f1_m: 0.4470 - val_precision_m: 0.4705 - val_recall_m: 0.4308\n",
      "Epoch 157/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0867 - acc: 0.9615 - f1_m: 0.9595 - precision_m: 0.9708 - recall_m: 0.9505 - val_loss: 4.2067 - val_acc: 0.4839 - val_f1_m: 0.4709 - val_precision_m: 0.5051 - val_recall_m: 0.4462\n",
      "Epoch 158/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1152 - acc: 0.9460 - f1_m: 0.9472 - precision_m: 0.9519 - recall_m: 0.9435 - val_loss: 4.1892 - val_acc: 0.4839 - val_f1_m: 0.4581 - val_precision_m: 0.4987 - val_recall_m: 0.4308\n",
      "Epoch 159/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1411 - acc: 0.9184 - f1_m: 0.9174 - precision_m: 0.9289 - recall_m: 0.9083 - val_loss: 4.0135 - val_acc: 0.4677 - val_f1_m: 0.4521 - val_precision_m: 0.4821 - val_recall_m: 0.4308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0606 - acc: 0.9825 - f1_m: 0.9800 - precision_m: 0.9872 - recall_m: 0.9743 - val_loss: 4.1174 - val_acc: 0.4677 - val_f1_m: 0.4556 - val_precision_m: 0.4897 - val_recall_m: 0.4308\n",
      "Epoch 161/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0609 - acc: 0.9904 - f1_m: 0.9830 - precision_m: 0.9904 - recall_m: 0.9770 - val_loss: 4.1645 - val_acc: 0.4677 - val_f1_m: 0.4598 - val_precision_m: 0.5026 - val_recall_m: 0.4308\n",
      "Epoch 162/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1049 - acc: 0.9665 - f1_m: 0.9526 - precision_m: 0.9676 - recall_m: 0.9406 - val_loss: 4.1087 - val_acc: 0.4677 - val_f1_m: 0.4675 - val_precision_m: 0.4974 - val_recall_m: 0.4462\n",
      "Epoch 163/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0520 - acc: 0.9773 - f1_m: 0.9777 - precision_m: 0.9804 - recall_m: 0.9755 - val_loss: 4.1543 - val_acc: 0.4677 - val_f1_m: 0.4786 - val_precision_m: 0.5256 - val_recall_m: 0.4462\n",
      "Epoch 164/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0717 - acc: 0.9591 - f1_m: 0.9616 - precision_m: 0.9669 - recall_m: 0.9574 - val_loss: 4.1608 - val_acc: 0.5000 - val_f1_m: 0.5051 - val_precision_m: 0.5436 - val_recall_m: 0.4769\n",
      "Epoch 165/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0954 - acc: 0.9640 - f1_m: 0.9641 - precision_m: 0.9642 - recall_m: 0.9640 - val_loss: 4.2562 - val_acc: 0.4839 - val_f1_m: 0.4829 - val_precision_m: 0.5128 - val_recall_m: 0.4615\n",
      "Epoch 166/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0563 - acc: 0.9773 - f1_m: 0.9773 - precision_m: 0.9773 - recall_m: 0.9773 - val_loss: 4.3049 - val_acc: 0.4839 - val_f1_m: 0.4829 - val_precision_m: 0.5128 - val_recall_m: 0.4615\n",
      "Epoch 167/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0525 - acc: 0.9760 - f1_m: 0.9735 - precision_m: 0.9760 - recall_m: 0.9716 - val_loss: 4.2988 - val_acc: 0.5000 - val_f1_m: 0.4987 - val_precision_m: 0.5308 - val_recall_m: 0.4769\n",
      "Epoch 168/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0887 - acc: 0.9376 - f1_m: 0.9453 - precision_m: 0.9556 - recall_m: 0.9370 - val_loss: 4.3363 - val_acc: 0.4839 - val_f1_m: 0.4833 - val_precision_m: 0.5154 - val_recall_m: 0.4615\n",
      "Epoch 169/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1870 - acc: 0.9397 - f1_m: 0.9480 - precision_m: 0.9582 - recall_m: 0.9397 - val_loss: 4.3989 - val_acc: 0.4677 - val_f1_m: 0.4624 - val_precision_m: 0.4859 - val_recall_m: 0.4462\n",
      "Epoch 170/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0666 - acc: 0.9722 - f1_m: 0.9732 - precision_m: 0.9744 - recall_m: 0.9722 - val_loss: 4.4324 - val_acc: 0.4677 - val_f1_m: 0.4624 - val_precision_m: 0.4859 - val_recall_m: 0.4462\n",
      "Epoch 171/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0576 - acc: 0.9829 - f1_m: 0.9810 - precision_m: 0.9829 - recall_m: 0.9795 - val_loss: 4.3565 - val_acc: 0.4839 - val_f1_m: 0.4812 - val_precision_m: 0.5090 - val_recall_m: 0.4615\n",
      "Epoch 172/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0704 - acc: 0.9743 - f1_m: 0.9707 - precision_m: 0.9808 - recall_m: 0.9625 - val_loss: 4.3938 - val_acc: 0.4839 - val_f1_m: 0.4812 - val_precision_m: 0.5090 - val_recall_m: 0.4615\n",
      "Epoch 173/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0730 - acc: 0.9821 - f1_m: 0.9809 - precision_m: 0.9820 - recall_m: 0.9800 - val_loss: 4.4564 - val_acc: 0.4839 - val_f1_m: 0.4812 - val_precision_m: 0.5090 - val_recall_m: 0.4615\n",
      "Epoch 174/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0905 - acc: 0.9570 - f1_m: 0.9480 - precision_m: 0.9537 - recall_m: 0.9435 - val_loss: 4.3132 - val_acc: 0.4839 - val_f1_m: 0.4863 - val_precision_m: 0.5205 - val_recall_m: 0.4615\n",
      "Epoch 175/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0546 - acc: 0.9766 - f1_m: 0.9801 - precision_m: 0.9848 - recall_m: 0.9764 - val_loss: 4.3668 - val_acc: 0.4839 - val_f1_m: 0.4863 - val_precision_m: 0.5205 - val_recall_m: 0.4615\n",
      "Epoch 176/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0654 - acc: 0.9742 - f1_m: 0.9772 - precision_m: 0.9809 - recall_m: 0.9742 - val_loss: 4.3883 - val_acc: 0.5000 - val_f1_m: 0.4983 - val_precision_m: 0.5282 - val_recall_m: 0.4769\n",
      "Epoch 177/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0654 - acc: 0.9793 - f1_m: 0.9800 - precision_m: 0.9870 - recall_m: 0.9745 - val_loss: 4.3899 - val_acc: 0.5000 - val_f1_m: 0.4821 - val_precision_m: 0.5141 - val_recall_m: 0.4615\n",
      "Epoch 178/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0528 - acc: 0.9845 - f1_m: 0.9852 - precision_m: 0.9862 - recall_m: 0.9845 - val_loss: 4.3722 - val_acc: 0.4839 - val_f1_m: 0.4902 - val_precision_m: 0.5308 - val_recall_m: 0.4615\n",
      "Epoch 179/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0966 - acc: 0.9538 - f1_m: 0.9567 - precision_m: 0.9604 - recall_m: 0.9538 - val_loss: 4.4038 - val_acc: 0.4839 - val_f1_m: 0.4812 - val_precision_m: 0.5090 - val_recall_m: 0.4615\n",
      "Epoch 180/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0637 - acc: 0.9813 - f1_m: 0.9821 - precision_m: 0.9848 - recall_m: 0.9802 - val_loss: 4.3412 - val_acc: 0.4677 - val_f1_m: 0.4692 - val_precision_m: 0.5013 - val_recall_m: 0.4462\n",
      "Epoch 181/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0650 - acc: 0.9783 - f1_m: 0.9813 - precision_m: 0.9908 - recall_m: 0.9738 - val_loss: 4.3972 - val_acc: 0.4677 - val_f1_m: 0.4594 - val_precision_m: 0.5000 - val_recall_m: 0.4308\n",
      "Epoch 182/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0559 - acc: 0.9796 - f1_m: 0.9828 - precision_m: 0.9878 - recall_m: 0.9788 - val_loss: 4.4301 - val_acc: 0.4677 - val_f1_m: 0.4504 - val_precision_m: 0.4782 - val_recall_m: 0.4308\n",
      "Epoch 183/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0533 - acc: 0.9935 - f1_m: 0.9860 - precision_m: 0.9935 - recall_m: 0.9800 - val_loss: 4.4030 - val_acc: 0.4677 - val_f1_m: 0.4581 - val_precision_m: 0.4731 - val_recall_m: 0.4462\n",
      "Epoch 184/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0526 - acc: 0.9899 - f1_m: 0.9895 - precision_m: 0.9899 - recall_m: 0.9891 - val_loss: 4.3355 - val_acc: 0.4839 - val_f1_m: 0.4761 - val_precision_m: 0.5167 - val_recall_m: 0.4462\n",
      "Epoch 185/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0770 - acc: 0.9546 - f1_m: 0.9577 - precision_m: 0.9616 - recall_m: 0.9546 - val_loss: 4.3674 - val_acc: 0.4677 - val_f1_m: 0.4598 - val_precision_m: 0.4769 - val_recall_m: 0.4462\n",
      "Epoch 186/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0683 - acc: 0.9773 - f1_m: 0.9772 - precision_m: 0.9849 - recall_m: 0.9710 - val_loss: 4.3849 - val_acc: 0.4839 - val_f1_m: 0.4769 - val_precision_m: 0.4962 - val_recall_m: 0.4615\n",
      "Epoch 187/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1025 - acc: 0.9617 - f1_m: 0.9607 - precision_m: 0.9703 - recall_m: 0.9531 - val_loss: 4.3535 - val_acc: 0.4839 - val_f1_m: 0.4863 - val_precision_m: 0.5205 - val_recall_m: 0.4615\n",
      "Epoch 188/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0747 - acc: 0.9721 - f1_m: 0.9619 - precision_m: 0.9721 - recall_m: 0.9537 - val_loss: 4.3980 - val_acc: 0.4839 - val_f1_m: 0.4863 - val_precision_m: 0.5205 - val_recall_m: 0.4615\n",
      "Epoch 189/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0491 - acc: 0.9722 - f1_m: 0.9753 - precision_m: 0.9793 - recall_m: 0.9722 - val_loss: 4.3797 - val_acc: 0.5000 - val_f1_m: 0.4910 - val_precision_m: 0.5359 - val_recall_m: 0.4615\n",
      "Epoch 190/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0517 - acc: 0.9840 - f1_m: 0.9799 - precision_m: 0.9843 - recall_m: 0.9764 - val_loss: 4.4200 - val_acc: 0.5323 - val_f1_m: 0.5295 - val_precision_m: 0.5615 - val_recall_m: 0.5077\n",
      "Epoch 191/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0495 - acc: 0.9871 - f1_m: 0.9884 - precision_m: 0.9901 - recall_m: 0.9871 - val_loss: 4.4659 - val_acc: 0.5161 - val_f1_m: 0.5060 - val_precision_m: 0.5231 - val_recall_m: 0.4923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0609 - acc: 0.9714 - f1_m: 0.9714 - precision_m: 0.9714 - recall_m: 0.9714 - val_loss: 4.4494 - val_acc: 0.4839 - val_f1_m: 0.4632 - val_precision_m: 0.4910 - val_recall_m: 0.4462\n",
      "Epoch 193/400\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.1230 - acc: 0.9528 - f1_m: 0.9533 - precision_m: 0.9603 - recall_m: 0.9477 - val_loss: 4.4355 - val_acc: 0.5000 - val_f1_m: 0.4838 - val_precision_m: 0.5179 - val_recall_m: 0.4615\n",
      "Epoch 194/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1125 - acc: 0.9558 - f1_m: 0.9558 - precision_m: 0.9584 - recall_m: 0.9537 - val_loss: 4.4641 - val_acc: 0.4839 - val_f1_m: 0.4726 - val_precision_m: 0.4897 - val_recall_m: 0.4615\n",
      "Epoch 195/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0788 - acc: 0.9512 - f1_m: 0.9532 - precision_m: 0.9558 - recall_m: 0.9512 - val_loss: 4.4935 - val_acc: 0.5000 - val_f1_m: 0.4829 - val_precision_m: 0.5128 - val_recall_m: 0.4615\n",
      "Epoch 196/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0678 - acc: 0.9686 - f1_m: 0.9686 - precision_m: 0.9686 - recall_m: 0.9686 - val_loss: 4.4810 - val_acc: 0.4839 - val_f1_m: 0.4735 - val_precision_m: 0.4885 - val_recall_m: 0.4615\n",
      "Epoch 197/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0515 - acc: 0.9933 - f1_m: 0.9904 - precision_m: 0.9933 - recall_m: 0.9881 - val_loss: 4.4088 - val_acc: 0.5000 - val_f1_m: 0.4769 - val_precision_m: 0.5218 - val_recall_m: 0.4462\n",
      "Epoch 198/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0709 - acc: 0.9766 - f1_m: 0.9737 - precision_m: 0.9766 - recall_m: 0.9714 - val_loss: 4.5453 - val_acc: 0.5000 - val_f1_m: 0.4645 - val_precision_m: 0.5115 - val_recall_m: 0.4308\n",
      "Epoch 199/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0639 - acc: 0.9689 - f1_m: 0.9685 - precision_m: 0.9708 - recall_m: 0.9667 - val_loss: 4.5091 - val_acc: 0.5000 - val_f1_m: 0.4936 - val_precision_m: 0.5192 - val_recall_m: 0.4769\n",
      "Epoch 200/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0620 - acc: 0.9774 - f1_m: 0.9774 - precision_m: 0.9774 - recall_m: 0.9774 - val_loss: 4.4647 - val_acc: 0.5000 - val_f1_m: 0.4901 - val_precision_m: 0.5423 - val_recall_m: 0.4615\n",
      "Epoch 201/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0758 - acc: 0.9709 - f1_m: 0.9722 - precision_m: 0.9754 - recall_m: 0.9697 - val_loss: 4.4944 - val_acc: 0.5000 - val_f1_m: 0.4778 - val_precision_m: 0.5013 - val_recall_m: 0.4615\n",
      "Epoch 202/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1399 - acc: 0.9418 - f1_m: 0.9394 - precision_m: 0.9420 - recall_m: 0.9373 - val_loss: 4.5537 - val_acc: 0.4839 - val_f1_m: 0.4585 - val_precision_m: 0.4756 - val_recall_m: 0.4462\n",
      "Epoch 203/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1420 - acc: 0.9448 - f1_m: 0.9268 - precision_m: 0.9403 - recall_m: 0.9161 - val_loss: 4.5311 - val_acc: 0.4839 - val_f1_m: 0.4778 - val_precision_m: 0.5013 - val_recall_m: 0.4615\n",
      "Epoch 204/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0633 - acc: 0.9680 - f1_m: 0.9679 - precision_m: 0.9680 - recall_m: 0.9678 - val_loss: 4.5907 - val_acc: 0.4839 - val_f1_m: 0.4778 - val_precision_m: 0.5013 - val_recall_m: 0.4615\n",
      "Epoch 205/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1060 - acc: 0.9576 - f1_m: 0.9675 - precision_m: 0.9799 - recall_m: 0.9576 - val_loss: 4.6245 - val_acc: 0.4677 - val_f1_m: 0.4513 - val_precision_m: 0.4833 - val_recall_m: 0.4308\n",
      "Epoch 206/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0852 - acc: 0.9539 - f1_m: 0.9562 - precision_m: 0.9610 - recall_m: 0.9523 - val_loss: 4.6649 - val_acc: 0.4839 - val_f1_m: 0.4833 - val_precision_m: 0.5154 - val_recall_m: 0.4615\n",
      "Epoch 207/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0700 - acc: 0.9545 - f1_m: 0.9512 - precision_m: 0.9545 - recall_m: 0.9485 - val_loss: 4.6334 - val_acc: 0.4839 - val_f1_m: 0.4799 - val_precision_m: 0.5077 - val_recall_m: 0.4615\n",
      "Epoch 208/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0872 - acc: 0.9642 - f1_m: 0.9580 - precision_m: 0.9642 - recall_m: 0.9530 - val_loss: 4.5869 - val_acc: 0.4677 - val_f1_m: 0.4688 - val_precision_m: 0.5051 - val_recall_m: 0.4462\n",
      "Epoch 209/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0750 - acc: 0.9726 - f1_m: 0.9738 - precision_m: 0.9802 - recall_m: 0.9687 - val_loss: 4.6501 - val_acc: 0.5000 - val_f1_m: 0.4833 - val_precision_m: 0.5154 - val_recall_m: 0.4615\n",
      "Epoch 210/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0874 - acc: 0.9627 - f1_m: 0.9596 - precision_m: 0.9631 - recall_m: 0.9570 - val_loss: 4.6500 - val_acc: 0.5000 - val_f1_m: 0.5004 - val_precision_m: 0.5346 - val_recall_m: 0.4769\n",
      "Epoch 211/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0475 - acc: 0.9844 - f1_m: 0.9880 - precision_m: 0.9939 - recall_m: 0.9844 - val_loss: 4.6471 - val_acc: 0.5161 - val_f1_m: 0.5047 - val_precision_m: 0.5474 - val_recall_m: 0.4769\n",
      "Epoch 212/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0388 - acc: 0.9797 - f1_m: 0.9808 - precision_m: 0.9826 - recall_m: 0.9794 - val_loss: 4.7147 - val_acc: 0.4839 - val_f1_m: 0.4825 - val_precision_m: 0.5167 - val_recall_m: 0.4615\n",
      "Epoch 213/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0345 - acc: 0.9815 - f1_m: 0.9851 - precision_m: 0.9921 - recall_m: 0.9794 - val_loss: 4.7296 - val_acc: 0.4839 - val_f1_m: 0.4842 - val_precision_m: 0.5205 - val_recall_m: 0.4615\n",
      "Epoch 214/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0484 - acc: 0.9803 - f1_m: 0.9797 - precision_m: 0.9901 - recall_m: 0.9714 - val_loss: 4.6973 - val_acc: 0.4839 - val_f1_m: 0.4748 - val_precision_m: 0.4962 - val_recall_m: 0.4615\n",
      "Epoch 215/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0645 - acc: 0.9689 - f1_m: 0.9689 - precision_m: 0.9689 - recall_m: 0.9689 - val_loss: 4.7767 - val_acc: 0.4839 - val_f1_m: 0.4748 - val_precision_m: 0.4962 - val_recall_m: 0.4615\n",
      "Epoch 216/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1069 - acc: 0.9734 - f1_m: 0.9734 - precision_m: 0.9734 - recall_m: 0.9734 - val_loss: 4.6722 - val_acc: 0.4839 - val_f1_m: 0.4701 - val_precision_m: 0.5064 - val_recall_m: 0.4462\n",
      "Epoch 217/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0978 - acc: 0.9575 - f1_m: 0.9566 - precision_m: 0.9610 - recall_m: 0.9530 - val_loss: 4.6366 - val_acc: 0.4677 - val_f1_m: 0.4436 - val_precision_m: 0.4628 - val_recall_m: 0.4308\n",
      "Epoch 218/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1049 - acc: 0.9466 - f1_m: 0.9466 - precision_m: 0.9466 - recall_m: 0.9466 - val_loss: 4.5827 - val_acc: 0.4839 - val_f1_m: 0.4645 - val_precision_m: 0.4923 - val_recall_m: 0.4462\n",
      "Epoch 219/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0596 - acc: 0.9779 - f1_m: 0.9760 - precision_m: 0.9779 - recall_m: 0.9745 - val_loss: 4.5280 - val_acc: 0.4839 - val_f1_m: 0.4850 - val_precision_m: 0.5192 - val_recall_m: 0.4615\n",
      "Epoch 220/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0933 - acc: 0.9615 - f1_m: 0.9617 - precision_m: 0.9619 - recall_m: 0.9615 - val_loss: 4.5658 - val_acc: 0.4677 - val_f1_m: 0.4624 - val_precision_m: 0.4859 - val_recall_m: 0.4462\n",
      "Epoch 221/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0666 - acc: 0.9762 - f1_m: 0.9718 - precision_m: 0.9867 - recall_m: 0.9599 - val_loss: 4.6242 - val_acc: 0.4677 - val_f1_m: 0.4585 - val_precision_m: 0.4756 - val_recall_m: 0.4462\n",
      "Epoch 222/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0857 - acc: 0.9624 - f1_m: 0.9613 - precision_m: 0.9624 - recall_m: 0.9604 - val_loss: 4.4265 - val_acc: 0.4839 - val_f1_m: 0.4829 - val_precision_m: 0.5128 - val_recall_m: 0.4615\n",
      "Epoch 223/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0752 - acc: 0.9798 - f1_m: 0.9809 - precision_m: 0.9824 - recall_m: 0.9798 - val_loss: 4.3964 - val_acc: 0.4839 - val_f1_m: 0.4624 - val_precision_m: 0.4859 - val_recall_m: 0.4462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0433 - acc: 0.9863 - f1_m: 0.9805 - precision_m: 0.9863 - recall_m: 0.9758 - val_loss: 4.3993 - val_acc: 0.5000 - val_f1_m: 0.4752 - val_precision_m: 0.4923 - val_recall_m: 0.4615\n",
      "Epoch 225/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0662 - acc: 0.9677 - f1_m: 0.9686 - precision_m: 0.9740 - recall_m: 0.9643 - val_loss: 4.4382 - val_acc: 0.5000 - val_f1_m: 0.4752 - val_precision_m: 0.4923 - val_recall_m: 0.4615\n",
      "Epoch 226/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0860 - acc: 0.9563 - f1_m: 0.9625 - precision_m: 0.9703 - recall_m: 0.9562 - val_loss: 4.5012 - val_acc: 0.5000 - val_f1_m: 0.4906 - val_precision_m: 0.5077 - val_recall_m: 0.4769\n",
      "Epoch 227/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0641 - acc: 0.9759 - f1_m: 0.9737 - precision_m: 0.9822 - recall_m: 0.9670 - val_loss: 4.5693 - val_acc: 0.5161 - val_f1_m: 0.5043 - val_precision_m: 0.5192 - val_recall_m: 0.4923\n",
      "Epoch 228/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0774 - acc: 0.9699 - f1_m: 0.9768 - precision_m: 0.9854 - recall_m: 0.9699 - val_loss: 4.5004 - val_acc: 0.4839 - val_f1_m: 0.4812 - val_precision_m: 0.5090 - val_recall_m: 0.4615\n",
      "Epoch 229/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0709 - acc: 0.9666 - f1_m: 0.9629 - precision_m: 0.9666 - recall_m: 0.9599 - val_loss: 4.5423 - val_acc: 0.5000 - val_f1_m: 0.4983 - val_precision_m: 0.5282 - val_recall_m: 0.4769\n",
      "Epoch 230/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0725 - acc: 0.9546 - f1_m: 0.9538 - precision_m: 0.9562 - recall_m: 0.9518 - val_loss: 4.7192 - val_acc: 0.4839 - val_f1_m: 0.4850 - val_precision_m: 0.5192 - val_recall_m: 0.4615\n",
      "Epoch 231/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1018 - acc: 0.9583 - f1_m: 0.9538 - precision_m: 0.9703 - recall_m: 0.9435 - val_loss: 4.6252 - val_acc: 0.5000 - val_f1_m: 0.4953 - val_precision_m: 0.5231 - val_recall_m: 0.4769\n",
      "Epoch 232/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0829 - acc: 0.9654 - f1_m: 0.9654 - precision_m: 0.9654 - recall_m: 0.9654 - val_loss: 4.6071 - val_acc: 0.5000 - val_f1_m: 0.4953 - val_precision_m: 0.5231 - val_recall_m: 0.4769\n",
      "Epoch 233/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0710 - acc: 0.9617 - f1_m: 0.9690 - precision_m: 0.9813 - recall_m: 0.9591 - val_loss: 4.6280 - val_acc: 0.4839 - val_f1_m: 0.4692 - val_precision_m: 0.5013 - val_recall_m: 0.4462\n",
      "Epoch 234/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0645 - acc: 0.9663 - f1_m: 0.9675 - precision_m: 0.9691 - recall_m: 0.9663 - val_loss: 4.7366 - val_acc: 0.5000 - val_f1_m: 0.4838 - val_precision_m: 0.5115 - val_recall_m: 0.4615\n",
      "Epoch 235/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0783 - acc: 0.9578 - f1_m: 0.9578 - precision_m: 0.9578 - recall_m: 0.9578 - val_loss: 4.7536 - val_acc: 0.4839 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 236/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0456 - acc: 0.9846 - f1_m: 0.9857 - precision_m: 0.9872 - recall_m: 0.9846 - val_loss: 4.7817 - val_acc: 0.4677 - val_f1_m: 0.4714 - val_precision_m: 0.5077 - val_recall_m: 0.4462\n",
      "Epoch 237/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0538 - acc: 0.9703 - f1_m: 0.9685 - precision_m: 0.9703 - recall_m: 0.9670 - val_loss: 4.6656 - val_acc: 0.4839 - val_f1_m: 0.4816 - val_precision_m: 0.5115 - val_recall_m: 0.4615\n",
      "Epoch 238/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0600 - acc: 0.9726 - f1_m: 0.9691 - precision_m: 0.9786 - recall_m: 0.9615 - val_loss: 4.5644 - val_acc: 0.5000 - val_f1_m: 0.5004 - val_precision_m: 0.5346 - val_recall_m: 0.4769\n",
      "Epoch 239/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0682 - acc: 0.9619 - f1_m: 0.9586 - precision_m: 0.9619 - recall_m: 0.9560 - val_loss: 4.6920 - val_acc: 0.4839 - val_f1_m: 0.4778 - val_precision_m: 0.5013 - val_recall_m: 0.4615\n",
      "Epoch 240/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.1248 - acc: 0.9391 - f1_m: 0.9413 - precision_m: 0.9441 - recall_m: 0.9391 - val_loss: 4.4864 - val_acc: 0.4839 - val_f1_m: 0.4684 - val_precision_m: 0.4769 - val_recall_m: 0.4615\n",
      "Epoch 241/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0602 - acc: 0.9678 - f1_m: 0.9662 - precision_m: 0.9672 - recall_m: 0.9655 - val_loss: 4.5015 - val_acc: 0.4839 - val_f1_m: 0.4547 - val_precision_m: 0.4654 - val_recall_m: 0.4462\n",
      "Epoch 242/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0479 - acc: 0.9782 - f1_m: 0.9810 - precision_m: 0.9844 - recall_m: 0.9782 - val_loss: 4.5106 - val_acc: 0.4839 - val_f1_m: 0.4752 - val_precision_m: 0.4923 - val_recall_m: 0.4615\n",
      "Epoch 243/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0744 - acc: 0.9611 - f1_m: 0.9622 - precision_m: 0.9637 - recall_m: 0.9611 - val_loss: 4.4661 - val_acc: 0.4516 - val_f1_m: 0.4534 - val_precision_m: 0.4897 - val_recall_m: 0.4308\n",
      "Epoch 244/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0739 - acc: 0.9799 - f1_m: 0.9753 - precision_m: 0.9809 - recall_m: 0.9708 - val_loss: 4.4187 - val_acc: 0.4677 - val_f1_m: 0.4688 - val_precision_m: 0.5051 - val_recall_m: 0.4462\n",
      "Epoch 245/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0878 - acc: 0.9503 - f1_m: 0.9522 - precision_m: 0.9546 - recall_m: 0.9503 - val_loss: 4.5290 - val_acc: 0.4839 - val_f1_m: 0.4684 - val_precision_m: 0.5026 - val_recall_m: 0.4462\n",
      "Epoch 246/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0444 - acc: 0.9763 - f1_m: 0.9768 - precision_m: 0.9778 - recall_m: 0.9760 - val_loss: 4.5426 - val_acc: 0.5000 - val_f1_m: 0.4966 - val_precision_m: 0.5244 - val_recall_m: 0.4769\n",
      "Epoch 247/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0969 - acc: 0.9638 - f1_m: 0.9593 - precision_m: 0.9750 - recall_m: 0.9467 - val_loss: 4.6584 - val_acc: 0.4839 - val_f1_m: 0.4679 - val_precision_m: 0.5000 - val_recall_m: 0.4462\n",
      "Epoch 248/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0855 - acc: 0.9454 - f1_m: 0.9472 - precision_m: 0.9551 - recall_m: 0.9409 - val_loss: 4.7867 - val_acc: 0.4516 - val_f1_m: 0.4521 - val_precision_m: 0.4821 - val_recall_m: 0.4308\n",
      "Epoch 249/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1083 - acc: 0.9434 - f1_m: 0.9428 - precision_m: 0.9432 - recall_m: 0.9425 - val_loss: 4.6736 - val_acc: 0.4839 - val_f1_m: 0.4726 - val_precision_m: 0.5090 - val_recall_m: 0.4462\n",
      "Epoch 250/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0768 - acc: 0.9602 - f1_m: 0.9640 - precision_m: 0.9687 - recall_m: 0.9602 - val_loss: 4.7233 - val_acc: 0.4355 - val_f1_m: 0.4295 - val_precision_m: 0.4487 - val_recall_m: 0.4154\n",
      "Epoch 251/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0999 - acc: 0.9360 - f1_m: 0.9340 - precision_m: 0.9357 - recall_m: 0.9326 - val_loss: 4.6583 - val_acc: 0.4677 - val_f1_m: 0.4551 - val_precision_m: 0.4679 - val_recall_m: 0.4462\n",
      "Epoch 252/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0620 - acc: 0.9693 - f1_m: 0.9730 - precision_m: 0.9775 - recall_m: 0.9693 - val_loss: 4.5945 - val_acc: 0.4516 - val_f1_m: 0.4432 - val_precision_m: 0.4603 - val_recall_m: 0.4308\n",
      "Epoch 253/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0546 - acc: 0.9830 - f1_m: 0.9828 - precision_m: 0.9830 - recall_m: 0.9827 - val_loss: 4.6079 - val_acc: 0.4677 - val_f1_m: 0.4585 - val_precision_m: 0.4756 - val_recall_m: 0.4462\n",
      "Epoch 254/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0814 - acc: 0.9460 - f1_m: 0.9509 - precision_m: 0.9599 - recall_m: 0.9437 - val_loss: 4.5703 - val_acc: 0.4677 - val_f1_m: 0.4551 - val_precision_m: 0.4679 - val_recall_m: 0.4462\n",
      "Epoch 255/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0884 - acc: 0.9599 - f1_m: 0.9625 - precision_m: 0.9658 - recall_m: 0.9599 - val_loss: 4.5940 - val_acc: 0.4677 - val_f1_m: 0.4530 - val_precision_m: 0.4615 - val_recall_m: 0.4462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0748 - acc: 0.9640 - f1_m: 0.9656 - precision_m: 0.9676 - recall_m: 0.9640 - val_loss: 4.5667 - val_acc: 0.4677 - val_f1_m: 0.4624 - val_precision_m: 0.4859 - val_recall_m: 0.4462\n",
      "Epoch 257/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0461 - acc: 0.9863 - f1_m: 0.9823 - precision_m: 0.9863 - recall_m: 0.9792 - val_loss: 4.5535 - val_acc: 0.4677 - val_f1_m: 0.4598 - val_precision_m: 0.4769 - val_recall_m: 0.4462\n",
      "Epoch 258/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0862 - acc: 0.9530 - f1_m: 0.9576 - precision_m: 0.9633 - recall_m: 0.9530 - val_loss: 4.6040 - val_acc: 0.4839 - val_f1_m: 0.4769 - val_precision_m: 0.4962 - val_recall_m: 0.4615\n",
      "Epoch 259/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0655 - acc: 0.9754 - f1_m: 0.9733 - precision_m: 0.9754 - recall_m: 0.9721 - val_loss: 4.7065 - val_acc: 0.4839 - val_f1_m: 0.4735 - val_precision_m: 0.4885 - val_recall_m: 0.4615\n",
      "Epoch 260/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0512 - acc: 0.9624 - f1_m: 0.9624 - precision_m: 0.9624 - recall_m: 0.9624 - val_loss: 4.7480 - val_acc: 0.4839 - val_f1_m: 0.4547 - val_precision_m: 0.4654 - val_recall_m: 0.4462\n",
      "Epoch 261/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0857 - acc: 0.9460 - f1_m: 0.9526 - precision_m: 0.9640 - recall_m: 0.9434 - val_loss: 4.7768 - val_acc: 0.4677 - val_f1_m: 0.4530 - val_precision_m: 0.4615 - val_recall_m: 0.4462\n",
      "Epoch 262/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0723 - acc: 0.9483 - f1_m: 0.9460 - precision_m: 0.9487 - recall_m: 0.9438 - val_loss: 4.7330 - val_acc: 0.4677 - val_f1_m: 0.4547 - val_precision_m: 0.4654 - val_recall_m: 0.4462\n",
      "Epoch 263/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0863 - acc: 0.9532 - f1_m: 0.9532 - precision_m: 0.9532 - recall_m: 0.9532 - val_loss: 4.7909 - val_acc: 0.4677 - val_f1_m: 0.4513 - val_precision_m: 0.4577 - val_recall_m: 0.4462\n",
      "Epoch 264/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0917 - acc: 0.9553 - f1_m: 0.9551 - precision_m: 0.9553 - recall_m: 0.9548 - val_loss: 4.7135 - val_acc: 0.4839 - val_f1_m: 0.4598 - val_precision_m: 0.4769 - val_recall_m: 0.4462\n",
      "Epoch 265/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0582 - acc: 0.9626 - f1_m: 0.9650 - precision_m: 0.9679 - recall_m: 0.9626 - val_loss: 4.7405 - val_acc: 0.4516 - val_f1_m: 0.4483 - val_precision_m: 0.4718 - val_recall_m: 0.4308\n",
      "Epoch 266/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0477 - acc: 0.9823 - f1_m: 0.9788 - precision_m: 0.9859 - recall_m: 0.9732 - val_loss: 4.7634 - val_acc: 0.4355 - val_f1_m: 0.4222 - val_precision_m: 0.4308 - val_recall_m: 0.4154\n",
      "Epoch 267/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0531 - acc: 0.9808 - f1_m: 0.9808 - precision_m: 0.9808 - recall_m: 0.9808 - val_loss: 4.7376 - val_acc: 0.4516 - val_f1_m: 0.4376 - val_precision_m: 0.4462 - val_recall_m: 0.4308\n",
      "Epoch 268/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0984 - acc: 0.9581 - f1_m: 0.9583 - precision_m: 0.9590 - recall_m: 0.9578 - val_loss: 4.7311 - val_acc: 0.4516 - val_f1_m: 0.4410 - val_precision_m: 0.4538 - val_recall_m: 0.4308\n",
      "Epoch 269/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0937 - acc: 0.9586 - f1_m: 0.9581 - precision_m: 0.9584 - recall_m: 0.9578 - val_loss: 4.6444 - val_acc: 0.4516 - val_f1_m: 0.4449 - val_precision_m: 0.4641 - val_recall_m: 0.4308\n",
      "Epoch 270/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0766 - acc: 0.9603 - f1_m: 0.9534 - precision_m: 0.9625 - recall_m: 0.9472 - val_loss: 4.6387 - val_acc: 0.4677 - val_f1_m: 0.4581 - val_precision_m: 0.4731 - val_recall_m: 0.4462\n",
      "Epoch 271/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0661 - acc: 0.9893 - f1_m: 0.9798 - precision_m: 0.9925 - recall_m: 0.9697 - val_loss: 4.6710 - val_acc: 0.4677 - val_f1_m: 0.4585 - val_precision_m: 0.4756 - val_recall_m: 0.4462\n",
      "Epoch 272/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0928 - acc: 0.9635 - f1_m: 0.9559 - precision_m: 0.9666 - recall_m: 0.9474 - val_loss: 4.6306 - val_acc: 0.4677 - val_f1_m: 0.4590 - val_precision_m: 0.4782 - val_recall_m: 0.4462\n",
      "Epoch 273/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0801 - acc: 0.9705 - f1_m: 0.9705 - precision_m: 0.9705 - recall_m: 0.9705 - val_loss: 4.6158 - val_acc: 0.4839 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 274/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0447 - acc: 0.9877 - f1_m: 0.9860 - precision_m: 0.9877 - recall_m: 0.9847 - val_loss: 4.6671 - val_acc: 0.4839 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 275/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0551 - acc: 0.9789 - f1_m: 0.9789 - precision_m: 0.9789 - recall_m: 0.9789 - val_loss: 4.6580 - val_acc: 0.4677 - val_f1_m: 0.4624 - val_precision_m: 0.4859 - val_recall_m: 0.4462\n",
      "Epoch 276/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1079 - acc: 0.9692 - f1_m: 0.9519 - precision_m: 0.9647 - recall_m: 0.9416 - val_loss: 4.6669 - val_acc: 0.4677 - val_f1_m: 0.4716 - val_precision_m: 0.5115 - val_recall_m: 0.4462\n",
      "Epoch 277/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0873 - acc: 0.9525 - f1_m: 0.9536 - precision_m: 0.9562 - recall_m: 0.9515 - val_loss: 4.6611 - val_acc: 0.4677 - val_f1_m: 0.4530 - val_precision_m: 0.4615 - val_recall_m: 0.4462\n",
      "Epoch 278/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0660 - acc: 0.9769 - f1_m: 0.9764 - precision_m: 0.9769 - recall_m: 0.9761 - val_loss: 4.7185 - val_acc: 0.4839 - val_f1_m: 0.4786 - val_precision_m: 0.5000 - val_recall_m: 0.4615\n",
      "Epoch 279/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0306 - acc: 0.9840 - f1_m: 0.9840 - precision_m: 0.9840 - recall_m: 0.9840 - val_loss: 4.7604 - val_acc: 0.4839 - val_f1_m: 0.4735 - val_precision_m: 0.4885 - val_recall_m: 0.4615\n",
      "Epoch 280/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0964 - acc: 0.9662 - f1_m: 0.9674 - precision_m: 0.9691 - recall_m: 0.9662 - val_loss: 4.6281 - val_acc: 0.4677 - val_f1_m: 0.4632 - val_precision_m: 0.4846 - val_recall_m: 0.4462\n",
      "Epoch 281/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0466 - acc: 0.9800 - f1_m: 0.9802 - precision_m: 0.9805 - recall_m: 0.9800 - val_loss: 4.6006 - val_acc: 0.4677 - val_f1_m: 0.4534 - val_precision_m: 0.4641 - val_recall_m: 0.4462\n",
      "Epoch 282/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1391 - acc: 0.9502 - f1_m: 0.9520 - precision_m: 0.9542 - recall_m: 0.9502 - val_loss: 4.5934 - val_acc: 0.5000 - val_f1_m: 0.4801 - val_precision_m: 0.5115 - val_recall_m: 0.4615\n",
      "Epoch 283/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0420 - acc: 0.9851 - f1_m: 0.9830 - precision_m: 0.9877 - recall_m: 0.9792 - val_loss: 4.6064 - val_acc: 0.4839 - val_f1_m: 0.4568 - val_precision_m: 0.4718 - val_recall_m: 0.4462\n",
      "Epoch 284/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0977 - acc: 0.9582 - f1_m: 0.9666 - precision_m: 0.9771 - recall_m: 0.9582 - val_loss: 4.6312 - val_acc: 0.4839 - val_f1_m: 0.4829 - val_precision_m: 0.5128 - val_recall_m: 0.4615\n",
      "Epoch 285/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0524 - acc: 0.9734 - f1_m: 0.9731 - precision_m: 0.9734 - recall_m: 0.9728 - val_loss: 4.6129 - val_acc: 0.4839 - val_f1_m: 0.4778 - val_precision_m: 0.5013 - val_recall_m: 0.4615\n",
      "Epoch 286/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0532 - acc: 0.9839 - f1_m: 0.9811 - precision_m: 0.9839 - recall_m: 0.9788 - val_loss: 4.6745 - val_acc: 0.4677 - val_f1_m: 0.4568 - val_precision_m: 0.4718 - val_recall_m: 0.4462\n",
      "Epoch 287/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0564 - acc: 0.9743 - f1_m: 0.9657 - precision_m: 0.9743 - recall_m: 0.9587 - val_loss: 4.6647 - val_acc: 0.4677 - val_f1_m: 0.4615 - val_precision_m: 0.4808 - val_recall_m: 0.4462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0452 - acc: 0.9920 - f1_m: 0.9842 - precision_m: 0.9920 - recall_m: 0.9780 - val_loss: 4.7628 - val_acc: 0.4677 - val_f1_m: 0.4581 - val_precision_m: 0.4731 - val_recall_m: 0.4462\n",
      "Epoch 289/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0805 - acc: 0.9588 - f1_m: 0.9565 - precision_m: 0.9686 - recall_m: 0.9469 - val_loss: 4.8450 - val_acc: 0.4516 - val_f1_m: 0.4444 - val_precision_m: 0.4615 - val_recall_m: 0.4308\n",
      "Epoch 290/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0600 - acc: 0.9727 - f1_m: 0.9713 - precision_m: 0.9727 - recall_m: 0.9701 - val_loss: 4.8535 - val_acc: 0.4839 - val_f1_m: 0.4791 - val_precision_m: 0.5026 - val_recall_m: 0.4615\n",
      "Epoch 291/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0429 - acc: 0.9892 - f1_m: 0.9892 - precision_m: 0.9892 - recall_m: 0.9892 - val_loss: 4.7765 - val_acc: 0.4677 - val_f1_m: 0.4598 - val_precision_m: 0.4769 - val_recall_m: 0.4462\n",
      "Epoch 292/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0466 - acc: 0.9786 - f1_m: 0.9797 - precision_m: 0.9809 - recall_m: 0.9786 - val_loss: 4.8452 - val_acc: 0.4516 - val_f1_m: 0.4444 - val_precision_m: 0.4615 - val_recall_m: 0.4308\n",
      "Epoch 293/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0551 - acc: 0.9755 - f1_m: 0.9817 - precision_m: 0.9895 - recall_m: 0.9755 - val_loss: 4.8403 - val_acc: 0.4516 - val_f1_m: 0.4359 - val_precision_m: 0.4423 - val_recall_m: 0.4308\n",
      "Epoch 294/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0633 - acc: 0.9657 - f1_m: 0.9557 - precision_m: 0.9657 - recall_m: 0.9477 - val_loss: 4.7939 - val_acc: 0.4516 - val_f1_m: 0.4359 - val_precision_m: 0.4423 - val_recall_m: 0.4308\n",
      "Epoch 295/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0707 - acc: 0.9760 - f1_m: 0.9760 - precision_m: 0.9760 - recall_m: 0.9760 - val_loss: 4.6386 - val_acc: 0.4355 - val_f1_m: 0.4269 - val_precision_m: 0.4462 - val_recall_m: 0.4154\n",
      "Epoch 296/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0689 - acc: 0.9520 - f1_m: 0.9493 - precision_m: 0.9510 - recall_m: 0.9480 - val_loss: 4.6338 - val_acc: 0.4677 - val_f1_m: 0.4568 - val_precision_m: 0.4718 - val_recall_m: 0.4462\n",
      "Epoch 297/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0459 - acc: 0.9819 - f1_m: 0.9819 - precision_m: 0.9819 - recall_m: 0.9819 - val_loss: 4.6236 - val_acc: 0.4839 - val_f1_m: 0.4637 - val_precision_m: 0.4872 - val_recall_m: 0.4462\n",
      "Epoch 298/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0607 - acc: 0.9698 - f1_m: 0.9697 - precision_m: 0.9718 - recall_m: 0.9680 - val_loss: 4.7295 - val_acc: 0.4677 - val_f1_m: 0.4547 - val_precision_m: 0.4910 - val_recall_m: 0.4308\n",
      "Epoch 299/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0453 - acc: 0.9901 - f1_m: 0.9886 - precision_m: 0.9901 - recall_m: 0.9874 - val_loss: 4.8530 - val_acc: 0.4677 - val_f1_m: 0.4551 - val_precision_m: 0.4679 - val_recall_m: 0.4462\n",
      "Epoch 300/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0278 - acc: 0.9906 - f1_m: 0.9925 - precision_m: 0.9949 - recall_m: 0.9906 - val_loss: 4.9835 - val_acc: 0.4677 - val_f1_m: 0.4551 - val_precision_m: 0.4679 - val_recall_m: 0.4462\n",
      "Epoch 301/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0373 - acc: 0.9863 - f1_m: 0.9849 - precision_m: 0.9890 - recall_m: 0.9816 - val_loss: 4.8618 - val_acc: 0.4677 - val_f1_m: 0.4628 - val_precision_m: 0.4885 - val_recall_m: 0.4462\n",
      "Epoch 302/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1032 - acc: 0.9560 - f1_m: 0.9487 - precision_m: 0.9564 - recall_m: 0.9425 - val_loss: 4.9521 - val_acc: 0.4677 - val_f1_m: 0.4658 - val_precision_m: 0.4936 - val_recall_m: 0.4462\n",
      "Epoch 303/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0504 - acc: 0.9732 - f1_m: 0.9736 - precision_m: 0.9748 - recall_m: 0.9729 - val_loss: 4.9714 - val_acc: 0.4677 - val_f1_m: 0.4658 - val_precision_m: 0.4936 - val_recall_m: 0.4462\n",
      "Epoch 304/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0620 - acc: 0.9734 - f1_m: 0.9770 - precision_m: 0.9816 - recall_m: 0.9733 - val_loss: 5.0282 - val_acc: 0.4677 - val_f1_m: 0.4598 - val_precision_m: 0.4769 - val_recall_m: 0.4462\n",
      "Epoch 305/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0927 - acc: 0.9596 - f1_m: 0.9679 - precision_m: 0.9783 - recall_m: 0.9596 - val_loss: 4.8947 - val_acc: 0.4677 - val_f1_m: 0.4615 - val_precision_m: 0.4808 - val_recall_m: 0.4462\n",
      "Epoch 306/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0566 - acc: 0.9844 - f1_m: 0.9740 - precision_m: 0.9844 - recall_m: 0.9657 - val_loss: 4.8948 - val_acc: 0.4677 - val_f1_m: 0.4650 - val_precision_m: 0.4885 - val_recall_m: 0.4462\n",
      "Epoch 307/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0676 - acc: 0.9777 - f1_m: 0.9777 - precision_m: 0.9777 - recall_m: 0.9777 - val_loss: 4.8619 - val_acc: 0.4839 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 308/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0762 - acc: 0.9463 - f1_m: 0.9367 - precision_m: 0.9463 - recall_m: 0.9290 - val_loss: 4.9019 - val_acc: 0.4839 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 309/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0557 - acc: 0.9730 - f1_m: 0.9730 - precision_m: 0.9730 - recall_m: 0.9730 - val_loss: 4.8737 - val_acc: 0.4839 - val_f1_m: 0.4667 - val_precision_m: 0.4923 - val_recall_m: 0.4462\n",
      "Epoch 310/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0586 - acc: 0.9770 - f1_m: 0.9756 - precision_m: 0.9770 - recall_m: 0.9744 - val_loss: 4.8995 - val_acc: 0.4839 - val_f1_m: 0.4769 - val_precision_m: 0.4962 - val_recall_m: 0.4615\n",
      "Epoch 311/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0595 - acc: 0.9689 - f1_m: 0.9715 - precision_m: 0.9746 - recall_m: 0.9689 - val_loss: 4.9727 - val_acc: 0.4677 - val_f1_m: 0.4650 - val_precision_m: 0.4885 - val_recall_m: 0.4462\n",
      "Epoch 312/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0809 - acc: 0.9614 - f1_m: 0.9581 - precision_m: 0.9657 - recall_m: 0.9521 - val_loss: 4.9391 - val_acc: 0.4677 - val_f1_m: 0.4615 - val_precision_m: 0.4808 - val_recall_m: 0.4462\n",
      "Epoch 313/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0827 - acc: 0.9684 - f1_m: 0.9666 - precision_m: 0.9684 - recall_m: 0.9652 - val_loss: 4.8091 - val_acc: 0.4516 - val_f1_m: 0.4534 - val_precision_m: 0.4833 - val_recall_m: 0.4308\n",
      "Epoch 314/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0954 - acc: 0.9654 - f1_m: 0.9564 - precision_m: 0.9627 - recall_m: 0.9513 - val_loss: 4.8395 - val_acc: 0.4677 - val_f1_m: 0.4603 - val_precision_m: 0.4795 - val_recall_m: 0.4462\n",
      "Epoch 315/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0435 - acc: 0.9759 - f1_m: 0.9720 - precision_m: 0.9759 - recall_m: 0.9689 - val_loss: 4.8769 - val_acc: 0.4677 - val_f1_m: 0.4650 - val_precision_m: 0.4885 - val_recall_m: 0.4462\n",
      "Epoch 316/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0873 - acc: 0.9465 - f1_m: 0.9446 - precision_m: 0.9519 - recall_m: 0.9388 - val_loss: 4.9306 - val_acc: 0.4516 - val_f1_m: 0.4444 - val_precision_m: 0.4615 - val_recall_m: 0.4308\n",
      "Epoch 317/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0703 - acc: 0.9713 - f1_m: 0.9718 - precision_m: 0.9723 - recall_m: 0.9713 - val_loss: 4.9638 - val_acc: 0.4677 - val_f1_m: 0.4650 - val_precision_m: 0.4885 - val_recall_m: 0.4462\n",
      "Epoch 318/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0548 - acc: 0.9770 - f1_m: 0.9776 - precision_m: 0.9789 - recall_m: 0.9766 - val_loss: 4.9284 - val_acc: 0.4677 - val_f1_m: 0.4564 - val_precision_m: 0.4692 - val_recall_m: 0.4462\n",
      "Epoch 319/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0836 - acc: 0.9777 - f1_m: 0.9606 - precision_m: 0.9824 - recall_m: 0.9432 - val_loss: 4.8896 - val_acc: 0.4677 - val_f1_m: 0.4479 - val_precision_m: 0.4692 - val_recall_m: 0.4308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0257 - acc: 0.9930 - f1_m: 0.9930 - precision_m: 0.9930 - recall_m: 0.9930 - val_loss: 4.9087 - val_acc: 0.4677 - val_f1_m: 0.4466 - val_precision_m: 0.4679 - val_recall_m: 0.4308\n",
      "Epoch 321/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0619 - acc: 0.9745 - f1_m: 0.9738 - precision_m: 0.9771 - recall_m: 0.9712 - val_loss: 4.8427 - val_acc: 0.4839 - val_f1_m: 0.4662 - val_precision_m: 0.4962 - val_recall_m: 0.4462\n",
      "Epoch 322/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0411 - acc: 0.9705 - f1_m: 0.9672 - precision_m: 0.9709 - recall_m: 0.9642 - val_loss: 4.8372 - val_acc: 0.4839 - val_f1_m: 0.4564 - val_precision_m: 0.4692 - val_recall_m: 0.4462\n",
      "Epoch 323/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.1192 - acc: 0.9471 - f1_m: 0.9482 - precision_m: 0.9497 - recall_m: 0.9471 - val_loss: 4.9128 - val_acc: 0.4677 - val_f1_m: 0.4483 - val_precision_m: 0.4718 - val_recall_m: 0.4308\n",
      "Epoch 324/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0484 - acc: 0.9892 - f1_m: 0.9897 - precision_m: 0.9903 - recall_m: 0.9892 - val_loss: 4.8931 - val_acc: 0.4839 - val_f1_m: 0.4564 - val_precision_m: 0.4692 - val_recall_m: 0.4462\n",
      "Epoch 325/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0812 - acc: 0.9691 - f1_m: 0.9555 - precision_m: 0.9691 - recall_m: 0.9472 - val_loss: 4.8096 - val_acc: 0.4839 - val_f1_m: 0.4590 - val_precision_m: 0.4782 - val_recall_m: 0.4462\n",
      "Epoch 326/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0401 - acc: 0.9779 - f1_m: 0.9841 - precision_m: 0.9919 - recall_m: 0.9779 - val_loss: 4.8539 - val_acc: 0.4677 - val_f1_m: 0.4483 - val_precision_m: 0.4718 - val_recall_m: 0.4308\n",
      "Epoch 327/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0386 - acc: 0.9816 - f1_m: 0.9816 - precision_m: 0.9816 - recall_m: 0.9816 - val_loss: 4.8694 - val_acc: 0.4839 - val_f1_m: 0.4551 - val_precision_m: 0.4679 - val_recall_m: 0.4462\n",
      "Epoch 328/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0642 - acc: 0.9739 - f1_m: 0.9750 - precision_m: 0.9765 - recall_m: 0.9739 - val_loss: 4.9509 - val_acc: 0.4839 - val_f1_m: 0.4667 - val_precision_m: 0.4731 - val_recall_m: 0.4615\n",
      "Epoch 329/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0847 - acc: 0.9475 - f1_m: 0.9497 - precision_m: 0.9525 - recall_m: 0.9475 - val_loss: 4.9580 - val_acc: 0.4839 - val_f1_m: 0.4671 - val_precision_m: 0.4756 - val_recall_m: 0.4615\n",
      "Epoch 330/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0637 - acc: 0.9610 - f1_m: 0.9604 - precision_m: 0.9610 - recall_m: 0.9599 - val_loss: 4.9043 - val_acc: 0.4839 - val_f1_m: 0.4594 - val_precision_m: 0.4808 - val_recall_m: 0.4462\n",
      "Epoch 331/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0710 - acc: 0.9607 - f1_m: 0.9607 - precision_m: 0.9607 - recall_m: 0.9607 - val_loss: 4.8331 - val_acc: 0.4839 - val_f1_m: 0.4705 - val_precision_m: 0.4833 - val_recall_m: 0.4615\n",
      "Epoch 332/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0514 - acc: 0.9813 - f1_m: 0.9772 - precision_m: 0.9813 - recall_m: 0.9740 - val_loss: 4.9410 - val_acc: 0.4839 - val_f1_m: 0.4664 - val_precision_m: 0.5000 - val_recall_m: 0.4462\n",
      "Epoch 333/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0422 - acc: 0.9768 - f1_m: 0.9797 - precision_m: 0.9835 - recall_m: 0.9768 - val_loss: 4.9403 - val_acc: 0.4677 - val_f1_m: 0.4463 - val_precision_m: 0.4756 - val_recall_m: 0.4308\n",
      "Epoch 334/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0362 - acc: 0.9851 - f1_m: 0.9838 - precision_m: 0.9851 - recall_m: 0.9828 - val_loss: 5.0298 - val_acc: 0.4677 - val_f1_m: 0.4504 - val_precision_m: 0.4782 - val_recall_m: 0.4308\n",
      "Epoch 335/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0479 - acc: 0.9769 - f1_m: 0.9769 - precision_m: 0.9769 - recall_m: 0.9769 - val_loss: 5.0171 - val_acc: 0.4839 - val_f1_m: 0.4611 - val_precision_m: 0.4846 - val_recall_m: 0.4462\n",
      "Epoch 336/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0586 - acc: 0.9672 - f1_m: 0.9657 - precision_m: 0.9666 - recall_m: 0.9650 - val_loss: 4.9908 - val_acc: 0.4839 - val_f1_m: 0.4778 - val_precision_m: 0.5013 - val_recall_m: 0.4615\n",
      "Epoch 337/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0413 - acc: 0.9869 - f1_m: 0.9871 - precision_m: 0.9876 - recall_m: 0.9866 - val_loss: 4.9234 - val_acc: 0.4516 - val_f1_m: 0.4444 - val_precision_m: 0.4615 - val_recall_m: 0.4308\n",
      "Epoch 338/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0463 - acc: 0.9859 - f1_m: 0.9859 - precision_m: 0.9859 - recall_m: 0.9859 - val_loss: 4.9389 - val_acc: 0.4677 - val_f1_m: 0.4585 - val_precision_m: 0.4756 - val_recall_m: 0.4462\n",
      "Epoch 339/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0770 - acc: 0.9670 - f1_m: 0.9675 - precision_m: 0.9680 - recall_m: 0.9670 - val_loss: 4.9833 - val_acc: 0.4677 - val_f1_m: 0.4585 - val_precision_m: 0.4756 - val_recall_m: 0.4462\n",
      "Epoch 340/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0454 - acc: 0.9817 - f1_m: 0.9822 - precision_m: 0.9830 - recall_m: 0.9817 - val_loss: 5.0431 - val_acc: 0.4677 - val_f1_m: 0.4637 - val_precision_m: 0.4872 - val_recall_m: 0.4462\n",
      "Epoch 341/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0350 - acc: 0.9936 - f1_m: 0.9936 - precision_m: 0.9936 - recall_m: 0.9936 - val_loss: 5.0358 - val_acc: 0.4839 - val_f1_m: 0.4624 - val_precision_m: 0.4859 - val_recall_m: 0.4462\n",
      "Epoch 342/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0418 - acc: 0.9848 - f1_m: 0.9848 - precision_m: 0.9848 - recall_m: 0.9848 - val_loss: 5.0861 - val_acc: 0.4839 - val_f1_m: 0.4709 - val_precision_m: 0.4859 - val_recall_m: 0.4615\n",
      "Epoch 343/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0432 - acc: 0.9886 - f1_m: 0.9866 - precision_m: 0.9886 - recall_m: 0.9849 - val_loss: 5.0995 - val_acc: 0.4839 - val_f1_m: 0.4744 - val_precision_m: 0.4936 - val_recall_m: 0.4615\n",
      "Epoch 344/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0587 - acc: 0.9853 - f1_m: 0.9853 - precision_m: 0.9853 - recall_m: 0.9853 - val_loss: 5.0633 - val_acc: 0.4677 - val_f1_m: 0.4547 - val_precision_m: 0.4654 - val_recall_m: 0.4462\n",
      "Epoch 345/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0549 - acc: 0.9766 - f1_m: 0.9744 - precision_m: 0.9838 - recall_m: 0.9670 - val_loss: 5.1251 - val_acc: 0.5000 - val_f1_m: 0.4786 - val_precision_m: 0.5000 - val_recall_m: 0.4615\n",
      "Epoch 346/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0656 - acc: 0.9688 - f1_m: 0.9664 - precision_m: 0.9688 - recall_m: 0.9645 - val_loss: 5.1887 - val_acc: 0.4839 - val_f1_m: 0.4615 - val_precision_m: 0.4808 - val_recall_m: 0.4462\n",
      "Epoch 347/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0501 - acc: 0.9713 - f1_m: 0.9728 - precision_m: 0.9747 - recall_m: 0.9713 - val_loss: 5.2086 - val_acc: 0.4516 - val_f1_m: 0.4239 - val_precision_m: 0.4346 - val_recall_m: 0.4154\n",
      "Epoch 348/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0468 - acc: 0.9702 - f1_m: 0.9691 - precision_m: 0.9702 - recall_m: 0.9681 - val_loss: 5.2719 - val_acc: 0.4516 - val_f1_m: 0.4308 - val_precision_m: 0.4500 - val_recall_m: 0.4154\n",
      "Epoch 349/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0663 - acc: 0.9740 - f1_m: 0.9778 - precision_m: 0.9848 - recall_m: 0.9722 - val_loss: 5.1417 - val_acc: 0.4516 - val_f1_m: 0.4205 - val_precision_m: 0.4269 - val_recall_m: 0.4154\n",
      "Epoch 350/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0277 - acc: 0.9862 - f1_m: 0.9862 - precision_m: 0.9862 - recall_m: 0.9862 - val_loss: 5.0388 - val_acc: 0.4516 - val_f1_m: 0.4239 - val_precision_m: 0.4346 - val_recall_m: 0.4154\n",
      "Epoch 351/400\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0708 - acc: 0.9622 - f1_m: 0.9607 - precision_m: 0.9622 - recall_m: 0.9594 - val_loss: 4.9755 - val_acc: 0.5000 - val_f1_m: 0.4756 - val_precision_m: 0.4949 - val_recall_m: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352/400\n",
      "49/49 [==============================] - 0s 7ms/step - loss: 0.0876 - acc: 0.9682 - f1_m: 0.9636 - precision_m: 0.9682 - recall_m: 0.9600 - val_loss: 4.7818 - val_acc: 0.4839 - val_f1_m: 0.4791 - val_precision_m: 0.5026 - val_recall_m: 0.4615\n",
      "Epoch 353/400\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0580 - acc: 0.9663 - f1_m: 0.9664 - precision_m: 0.9713 - recall_m: 0.9625 - val_loss: 4.7756 - val_acc: 0.4839 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 354/400\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.0671 - acc: 0.9787 - f1_m: 0.9650 - precision_m: 0.9787 - recall_m: 0.9540 - val_loss: 4.7258 - val_acc: 0.4839 - val_f1_m: 0.4752 - val_precision_m: 0.4923 - val_recall_m: 0.4615\n",
      "Epoch 355/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0717 - acc: 0.9604 - f1_m: 0.9613 - precision_m: 0.9625 - recall_m: 0.9604 - val_loss: 4.8121 - val_acc: 0.4839 - val_f1_m: 0.4701 - val_precision_m: 0.4808 - val_recall_m: 0.4615\n",
      "Epoch 356/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0428 - acc: 0.9839 - f1_m: 0.9860 - precision_m: 0.9930 - recall_m: 0.9805 - val_loss: 4.8545 - val_acc: 0.4839 - val_f1_m: 0.4598 - val_precision_m: 0.4769 - val_recall_m: 0.4462\n",
      "Epoch 357/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0488 - acc: 0.9875 - f1_m: 0.9841 - precision_m: 0.9875 - recall_m: 0.9814 - val_loss: 4.8170 - val_acc: 0.4839 - val_f1_m: 0.4598 - val_precision_m: 0.4769 - val_recall_m: 0.4462\n",
      "Epoch 358/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0379 - acc: 0.9853 - f1_m: 0.9853 - precision_m: 0.9853 - recall_m: 0.9853 - val_loss: 4.8219 - val_acc: 0.4839 - val_f1_m: 0.4620 - val_precision_m: 0.4833 - val_recall_m: 0.4462\n",
      "Epoch 359/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0428 - acc: 0.9833 - f1_m: 0.9858 - precision_m: 0.9889 - recall_m: 0.9833 - val_loss: 4.8242 - val_acc: 0.4839 - val_f1_m: 0.4620 - val_precision_m: 0.4833 - val_recall_m: 0.4462\n",
      "Epoch 360/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0564 - acc: 0.9651 - f1_m: 0.9588 - precision_m: 0.9667 - recall_m: 0.9525 - val_loss: 4.8473 - val_acc: 0.4677 - val_f1_m: 0.4598 - val_precision_m: 0.4769 - val_recall_m: 0.4462\n",
      "Epoch 361/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0362 - acc: 0.9895 - f1_m: 0.9895 - precision_m: 0.9895 - recall_m: 0.9895 - val_loss: 4.7961 - val_acc: 0.4677 - val_f1_m: 0.4620 - val_precision_m: 0.4833 - val_recall_m: 0.4462\n",
      "Epoch 362/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0503 - acc: 0.9746 - f1_m: 0.9666 - precision_m: 0.9748 - recall_m: 0.9601 - val_loss: 4.7791 - val_acc: 0.4839 - val_f1_m: 0.4812 - val_precision_m: 0.5090 - val_recall_m: 0.4615\n",
      "Epoch 363/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0709 - acc: 0.9626 - f1_m: 0.9556 - precision_m: 0.9626 - recall_m: 0.9500 - val_loss: 4.8294 - val_acc: 0.4677 - val_f1_m: 0.4658 - val_precision_m: 0.4936 - val_recall_m: 0.4462\n",
      "Epoch 364/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0236 - acc: 0.9945 - f1_m: 0.9944 - precision_m: 0.9945 - recall_m: 0.9943 - val_loss: 4.7641 - val_acc: 0.4839 - val_f1_m: 0.4658 - val_precision_m: 0.4936 - val_recall_m: 0.4462\n",
      "Epoch 365/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0387 - acc: 0.9815 - f1_m: 0.9798 - precision_m: 0.9815 - recall_m: 0.9785 - val_loss: 4.7539 - val_acc: 0.4839 - val_f1_m: 0.4735 - val_precision_m: 0.4885 - val_recall_m: 0.4615\n",
      "Epoch 366/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0429 - acc: 0.9815 - f1_m: 0.9815 - precision_m: 0.9815 - recall_m: 0.9815 - val_loss: 4.7518 - val_acc: 0.4839 - val_f1_m: 0.4778 - val_precision_m: 0.5013 - val_recall_m: 0.4615\n",
      "Epoch 367/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0533 - acc: 0.9714 - f1_m: 0.9714 - precision_m: 0.9714 - recall_m: 0.9714 - val_loss: 4.7363 - val_acc: 0.4839 - val_f1_m: 0.4752 - val_precision_m: 0.4923 - val_recall_m: 0.4615\n",
      "Epoch 368/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0304 - acc: 0.9919 - f1_m: 0.9919 - precision_m: 0.9919 - recall_m: 0.9919 - val_loss: 4.7566 - val_acc: 0.4839 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 369/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0546 - acc: 0.9535 - f1_m: 0.9536 - precision_m: 0.9546 - recall_m: 0.9528 - val_loss: 4.7957 - val_acc: 0.5000 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 370/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0545 - acc: 0.9704 - f1_m: 0.9669 - precision_m: 0.9731 - recall_m: 0.9619 - val_loss: 4.7817 - val_acc: 0.4839 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 371/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0346 - acc: 0.9909 - f1_m: 0.9889 - precision_m: 0.9979 - recall_m: 0.9818 - val_loss: 4.8355 - val_acc: 0.4839 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 372/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0611 - acc: 0.9596 - f1_m: 0.9596 - precision_m: 0.9596 - recall_m: 0.9596 - val_loss: 4.7775 - val_acc: 0.4839 - val_f1_m: 0.4598 - val_precision_m: 0.4769 - val_recall_m: 0.4462\n",
      "Epoch 373/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0442 - acc: 0.9807 - f1_m: 0.9807 - precision_m: 0.9807 - recall_m: 0.9807 - val_loss: 4.8262 - val_acc: 0.4516 - val_f1_m: 0.4444 - val_precision_m: 0.4615 - val_recall_m: 0.4308\n",
      "Epoch 374/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0485 - acc: 0.9751 - f1_m: 0.9703 - precision_m: 0.9733 - recall_m: 0.9680 - val_loss: 4.9376 - val_acc: 0.4839 - val_f1_m: 0.4568 - val_precision_m: 0.4718 - val_recall_m: 0.4462\n",
      "Epoch 375/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0735 - acc: 0.9524 - f1_m: 0.9524 - precision_m: 0.9524 - recall_m: 0.9524 - val_loss: 5.0000 - val_acc: 0.4839 - val_f1_m: 0.4568 - val_precision_m: 0.4718 - val_recall_m: 0.4462\n",
      "Epoch 376/400\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 0.0567 - acc: 0.9618 - f1_m: 0.9618 - precision_m: 0.9618 - recall_m: 0.9618 - val_loss: 5.1088 - val_acc: 0.4839 - val_f1_m: 0.4684 - val_precision_m: 0.4769 - val_recall_m: 0.4615\n",
      "Epoch 377/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0432 - acc: 0.9719 - f1_m: 0.9719 - precision_m: 0.9719 - recall_m: 0.9719 - val_loss: 5.0923 - val_acc: 0.4839 - val_f1_m: 0.4684 - val_precision_m: 0.4769 - val_recall_m: 0.4615\n",
      "Epoch 378/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0632 - acc: 0.9939 - f1_m: 0.9842 - precision_m: 0.9939 - recall_m: 0.9765 - val_loss: 5.2242 - val_acc: 0.4677 - val_f1_m: 0.4496 - val_precision_m: 0.4538 - val_recall_m: 0.4462\n",
      "Epoch 379/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0486 - acc: 0.9769 - f1_m: 0.9769 - precision_m: 0.9769 - recall_m: 0.9769 - val_loss: 5.2169 - val_acc: 0.4516 - val_f1_m: 0.4342 - val_precision_m: 0.4385 - val_recall_m: 0.4308\n",
      "Epoch 380/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0990 - acc: 0.9534 - f1_m: 0.9538 - precision_m: 0.9542 - recall_m: 0.9534 - val_loss: 5.0007 - val_acc: 0.4839 - val_f1_m: 0.4547 - val_precision_m: 0.4654 - val_recall_m: 0.4462\n",
      "Epoch 381/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0629 - acc: 0.9666 - f1_m: 0.9689 - precision_m: 0.9762 - recall_m: 0.9630 - val_loss: 4.9170 - val_acc: 0.4839 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 382/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0327 - acc: 0.9818 - f1_m: 0.9818 - precision_m: 0.9823 - recall_m: 0.9813 - val_loss: 4.9408 - val_acc: 0.4839 - val_f1_m: 0.4735 - val_precision_m: 0.4885 - val_recall_m: 0.4615\n",
      "Epoch 383/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0709 - acc: 0.9521 - f1_m: 0.9521 - precision_m: 0.9521 - recall_m: 0.9521 - val_loss: 4.9168 - val_acc: 0.4839 - val_f1_m: 0.4684 - val_precision_m: 0.4769 - val_recall_m: 0.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0485 - acc: 0.9564 - f1_m: 0.9589 - precision_m: 0.9621 - recall_m: 0.9564 - val_loss: 4.9545 - val_acc: 0.4677 - val_f1_m: 0.4564 - val_precision_m: 0.4692 - val_recall_m: 0.4462\n",
      "Epoch 385/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0374 - acc: 0.9881 - f1_m: 0.9881 - precision_m: 0.9881 - recall_m: 0.9881 - val_loss: 5.0110 - val_acc: 0.4839 - val_f1_m: 0.4684 - val_precision_m: 0.4769 - val_recall_m: 0.4615\n",
      "Epoch 386/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0398 - acc: 0.9827 - f1_m: 0.9819 - precision_m: 0.9827 - recall_m: 0.9814 - val_loss: 4.9798 - val_acc: 0.4839 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 387/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0380 - acc: 0.9853 - f1_m: 0.9853 - precision_m: 0.9875 - recall_m: 0.9835 - val_loss: 4.9839 - val_acc: 0.4839 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 388/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0606 - acc: 0.9737 - f1_m: 0.9701 - precision_m: 0.9737 - recall_m: 0.9673 - val_loss: 4.8951 - val_acc: 0.4839 - val_f1_m: 0.4756 - val_precision_m: 0.4949 - val_recall_m: 0.4615\n",
      "Epoch 389/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0292 - acc: 0.9895 - f1_m: 0.9898 - precision_m: 0.9915 - recall_m: 0.9884 - val_loss: 4.9341 - val_acc: 0.4677 - val_f1_m: 0.4654 - val_precision_m: 0.4910 - val_recall_m: 0.4462\n",
      "Epoch 390/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0742 - acc: 0.9730 - f1_m: 0.9693 - precision_m: 0.9730 - recall_m: 0.9663 - val_loss: 4.9681 - val_acc: 0.4677 - val_f1_m: 0.4632 - val_precision_m: 0.4846 - val_recall_m: 0.4462\n",
      "Epoch 391/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0728 - acc: 0.9682 - f1_m: 0.9693 - precision_m: 0.9732 - recall_m: 0.9661 - val_loss: 4.9276 - val_acc: 0.4677 - val_f1_m: 0.4509 - val_precision_m: 0.4808 - val_recall_m: 0.4308\n",
      "Epoch 392/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0889 - acc: 0.9573 - f1_m: 0.9573 - precision_m: 0.9573 - recall_m: 0.9573 - val_loss: 4.9803 - val_acc: 0.4677 - val_f1_m: 0.4658 - val_precision_m: 0.4936 - val_recall_m: 0.4462\n",
      "Epoch 393/400\n",
      "49/49 [==============================] - 0s 3ms/step - loss: 0.0611 - acc: 0.9723 - f1_m: 0.9725 - precision_m: 0.9728 - recall_m: 0.9723 - val_loss: 4.9715 - val_acc: 0.4677 - val_f1_m: 0.4650 - val_precision_m: 0.4885 - val_recall_m: 0.4462\n",
      "Epoch 394/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0415 - acc: 0.9861 - f1_m: 0.9871 - precision_m: 0.9883 - recall_m: 0.9861 - val_loss: 5.1098 - val_acc: 0.4516 - val_f1_m: 0.4444 - val_precision_m: 0.4615 - val_recall_m: 0.4308\n",
      "Epoch 395/400\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 0.0569 - acc: 0.9781 - f1_m: 0.9782 - precision_m: 0.9795 - recall_m: 0.9772 - val_loss: 5.1126 - val_acc: 0.4677 - val_f1_m: 0.4530 - val_precision_m: 0.4615 - val_recall_m: 0.4462\n",
      "Epoch 396/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0748 - acc: 0.9617 - f1_m: 0.9651 - precision_m: 0.9693 - recall_m: 0.9617 - val_loss: 5.0914 - val_acc: 0.4677 - val_f1_m: 0.4581 - val_precision_m: 0.4731 - val_recall_m: 0.4462\n",
      "Epoch 397/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0665 - acc: 0.9748 - f1_m: 0.9748 - precision_m: 0.9748 - recall_m: 0.9748 - val_loss: 5.1047 - val_acc: 0.4677 - val_f1_m: 0.4632 - val_precision_m: 0.4846 - val_recall_m: 0.4462\n",
      "Epoch 398/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0539 - acc: 0.9809 - f1_m: 0.9811 - precision_m: 0.9865 - recall_m: 0.9769 - val_loss: 5.0344 - val_acc: 0.4677 - val_f1_m: 0.4598 - val_precision_m: 0.4769 - val_recall_m: 0.4462\n",
      "Epoch 399/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0448 - acc: 0.9784 - f1_m: 0.9784 - precision_m: 0.9784 - recall_m: 0.9784 - val_loss: 5.0326 - val_acc: 0.4839 - val_f1_m: 0.4718 - val_precision_m: 0.4846 - val_recall_m: 0.4615\n",
      "Epoch 400/400\n",
      "49/49 [==============================] - 0s 4ms/step - loss: 0.0240 - acc: 0.9921 - f1_m: 0.9921 - precision_m: 0.9921 - recall_m: 0.9921 - val_loss: 5.0281 - val_acc: 0.4839 - val_f1_m: 0.4684 - val_precision_m: 0.4769 - val_recall_m: 0.4615\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "#fitting and saving the model \n",
    "hist = model.fit(X_train, Y_train, epochs=400, batch_size=5, verbose=1, validation_data=(X_test, Y_test))\n",
    "model.save('chatbot_model.h5', hist)\n",
    "\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.50\n",
      "Validation accuracy: 0.55\n",
      "F-1 score: 0.55\n",
      "Precision: 0.56\n",
      "Recall: 0.55\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Loss: {:.2f}\".format(loss))\n",
    "print(\"Validation accuracy: {:.2f}\".format(accuracy))\n",
    "print(\"F-1 score: {:.2f}\".format(f1_score))\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
